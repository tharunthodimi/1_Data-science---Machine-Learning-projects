{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing Required libraries for our Analysis\n",
    "\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filter warnings: import warnings to avoid unnecessary runtime warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using pandas setoption to display all the columns and rows to have a clear view of data in  further steps\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Reading the train.csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the csv file and storing in data variable,And displaying the top5 rows of data\n",
    "\n",
    "data=pd.read_csv('train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shape of the dataframe\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation:\n",
    "- We have 1460 rows and 81 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical Description of the data\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- From the above statistical descripton count of some numerical columns are less than the normal count of 1460.\n",
    "- `LotFrontage`,`MasvnrArea` and `GarageYrBlt` features required null value treatment which will be done in further steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display non-null count ,datatype of each feature\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- Total number of features we have is 81.\n",
    "- We have Features containing datatype of `int`,`object` and `float`\n",
    "- We can see see some of the columns have null values.we will treat them in further steps.some of them are `PoolQc`,`Fencce`,`MiscFeature`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Data Preparation and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Percentage of null values present in each column(or) feature\n",
    "\n",
    "data.isnull().sum()/data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- In the above step we have clear view of null value percentage of each feature in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets sort the Percentage of null values for easy represenataion of the data\n",
    "#nullval_per holds null value percentage of each column\n",
    "\n",
    "nullval_per=data.isnull().sum()/data.shape[0]\n",
    "nullval_per.sort_values(ascending=False)[:20]   #Display the column names of Top 20 highest null value percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "- In the above step we are displaying the features null value percentage in descending order.\n",
    "- Lets drop features/columns having null value percentage greater than 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considering only the columns with less than 30 percentage of null values for our analysis\n",
    "newcolumns=nullval_per[nullval_per<0.3]\n",
    "newcolumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe `data2` considering features where null value percentage is less than 30 percent\n",
    "data2=data[newcolumns.index]\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- We have created new dataframe called `data2` which holds features where null value percentage is less than 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping id column\n",
    "data2=data2.iloc[:,1:]\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insights:\n",
    "- Id column has been dropped since it will not help in our analysis considering this feature may mislead the analysis\n",
    "- we are having 75 columns/features,lets consider further analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null value Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `NullValuecolumns` here holds the features having null value percentage greater than 0\n",
    "nullval_per=data2.isnull().sum()/data2.shape[0]\n",
    "NullValuecolumns=nullval_per[nullval_per>0.0].sort_values(ascending=False)\n",
    "print(NullValuecolumns)\n",
    "print()\n",
    "print(\"Count of features having null values:\",len(NullValuecolumns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- We have 14 features having null vlaues in it.\n",
    "- In the next step all the features names will be displayed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NullValuecolumns.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets understand the datatype of the column,which helps us in treating outliers on the same\n",
    "\n",
    "data2[NullValuecolumns.index].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- We can treat the outliers present in the above column since now we are aware of teh datatype of that feature\n",
    "- We will follow the following approach :\n",
    "    - Columns having null values in  `Numerical` columns will be replaced with Median values of that feature.\n",
    "    - Columns having null values in  `Categorical` columns will be replaced based on the information we have from data dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat the numeric columns by replacing nan values with median values\n",
    "\n",
    "data2['LotFrontage'] = data2['LotFrontage'].replace(np.NaN,data2['LotFrontage'].median())\n",
    "data2['MasVnrArea'] = data2['MasVnrArea'].replace(np.NaN,data2['MasVnrArea'].median())\n",
    "data2['GarageYrBlt'] = data2['GarageYrBlt'].replace(np.NaN,data2['GarageYrBlt'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets verify the null value count after performing null value treatment in the previous step\n",
    "\n",
    "data2[['LotFrontage','MasVnrArea','GarageYrBlt']].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Insights:\n",
    "- Null values in the above numeical columns has been treated successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets validate Nullvalue percentage again\n",
    "nullval_per=data2.isnull().sum()/data2.shape[0]\n",
    "NullValuecolumns=nullval_per[nullval_per>0.0].sort_values(ascending=False)\n",
    "NullValuecolumns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- Lets treat the above categorical values in the next steps in  which null values has been observed as shown above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets visualize the categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NullValuecolumns.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## All the abve columns will be visualised to understand the spread of categories in the categorical features\n",
    "counter=range(1,len(NullValuecolumns)+1)\n",
    "plt.figure(figsize=(18,50))\n",
    "for i,j in zip(NullValuecolumns.index,counter):\n",
    "    plt.subplot(6,2,j)\n",
    "    plt.title(i,fontdict={'fontsize':15,'color':'green'})\n",
    "    sns.countplot(i,data=data2)\n",
    "    plt.xticks(rotation=90,size=12,color='red')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From data dictionary we know that nan values in these columns indicate No Garage so lets replace nan values with NoGarage category\n",
    "#  In the following categories : 'GarageCond', 'GarageQual', 'GarageFinish', 'GarageType',Lets replace nan values with `No garage` categroy\n",
    "\n",
    "data2['GarageCond']=data2['GarageCond'].replace(np.NaN,'No Garage')\n",
    "data2['GarageQual']=data2['GarageQual'].replace(np.NaN,'No Garage')\n",
    "data2['GarageFinish']=data2['GarageFinish'].replace(np.NaN,'No Garage')\n",
    "data2['GarageType']=data2['GarageType'].replace(np.NaN,'No Garage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- We have treated null values present in the Garage related columns and treated nan values with `No Garage` Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From data dictionary we know that nan values in these columns indicate No basement so lets replace nan values with No Basement category\n",
    "# In the following categories : 'BsmtFinType2', 'BsmtExposure', 'BsmtFinType1', 'BsmtCond', 'BsmtQual',Lets replace nan values with `No Basement` categroy\n",
    "\n",
    "data2['BsmtFinType2']=data2['BsmtFinType2'].replace(np.NaN,'No Basement')\n",
    "data2['BsmtExposure']=data2['BsmtExposure'].replace(np.NaN,'No Basement')\n",
    "data2['BsmtFinType1']=data2['BsmtFinType1'].replace(np.NaN,'No Basement')\n",
    "data2['BsmtCond']=data2['BsmtCond'].replace(np.NaN,'No Basement')\n",
    "data2['BsmtQual']=data2['BsmtQual'].replace(np.NaN,'No Basement')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- We have treated null values present in the Garage related columns and replaced nan values with ` No Basement` category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Replacing nan values with mode(Highests occurence) value\n",
    "\n",
    "data2['MasVnrType']=data2['MasVnrType'].replace(np.NaN,data2['MasVnrType'].mode()[0])\n",
    "data2['Electrical']=data2['Electrical'].replace(np.NaN,data2['Electrical'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- Replacing nan values in `MasVnrType` an `Electrical` with highest occurence category in the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets validate the null value count \n",
    "print(data2.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As shown above null value count is 0 in all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As shown above all the 75 features are now validated for null values and no null values are present in the above features,lets continue our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From data dictionary we know that feature: MSSubClass is a categorical column represented in numerical form lets convert back to original representation which helps in EDA\n",
    "\n",
    "\n",
    "data2['MSSubClass']=data2['MSSubClass'].replace(\n",
    "    {20:'1-STORY 1946 & NEWER ALL STYLES',\n",
    "     30:'1-STORY 1945 & OLDER',\n",
    "     40:'1-STORY W/FINISHED ATTIC ALL AGES',\n",
    "     45:'1-1/2 STORY - UNFINISHED ALL AGES',\n",
    "     50:'1-1/2 STORY FINISHED ALL AGES',\n",
    "     60:'2-STORY 1946 & NEWER',\n",
    "     70:'2-STORY 1945 & OLDER',\n",
    "     75:'2-1/2 STORY ALL AGES',\n",
    "     80:'SPLIT OR MULTI-LEVEL',\n",
    "     85:'SPLIT FOYER',\n",
    "     90:'DUPLEX - ALL STYLES AND AGES',\n",
    "     120:'1-STORY PUD (Planned Unit Development) - 1946 & NEWER',\n",
    "     150:'1-1/2 STORY PUD - ALL AGES',\n",
    "     160:'2-STORY PUD - 1946 & NEWER',\n",
    "     180:'PUD - MULTILEVEL - INCL SPLIT LEV/FOYER',\n",
    "     190:'2 FAMILY CONVERSION - ALL STYLES AND AGES'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- Feature: `MSSubClass` is a categorical column represented in numerical form lets convert back to original representation which helps in EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets treat `OverallQual` and `OverallCond` whicha re in numericla in nature but from data dictionary they represnt cateories of goodness measure\n",
    "# values is a reusable method which when called convert the features into categories when numerical columns where given\n",
    "\n",
    "values={10:'Very Excellent',\n",
    " 9:'Excellent',\n",
    " 8:'Very Good',\n",
    " 7:'Good',\n",
    " 6:'Above Average',\n",
    " 5:'Average',\n",
    " 4:'Below Average',\n",
    " 3:'Fair',\n",
    " 2:'Poor',\n",
    " 1:'Very Poor'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- Reusable methods are created which helps in converting the features `overallQual` and `overallcond` to its original format specified in data dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OverallQual: Rates the overall material and finish of the house\n",
    "# OverallCond: Rates the overall condition of the house\n",
    "\n",
    "data2['OverallQual']=data2['OverallQual'].replace(values)\n",
    "data2['OverallCond']=data2['OverallCond'].replace(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[['MSSubClass','OverallQual','OverallCond']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[['MSSubClass','OverallQual','OverallCond']].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- We have treated the nan values and converted features like `MsSubClass`,`OverallQual` and `OverallCond` to the required format for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets have a check at Target Column : SalePrice\n",
    "# lets plot distribution plot for the target column \n",
    "\n",
    "sns.distplot(data2['SalePrice'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As observed data is right skewed and this is quite common in `SalesPrice` columns where few products/houses will have higher price  due to various factors.\n",
    "- We need to treat this else model will get impacted because of the skewed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['SalePrice']=np.log(data2['SalePrice'])\n",
    "data2['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets visualise the distribution plot for saleprice feature afer aplying tge log transfrmation\n",
    "sns.distplot(data2['SalePrice'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As observed in the above distribution plot we have reduceed the skewness of teh data by applying log transformation.\n",
    "- Due to this transformation we have a better results and results may not get deviated.\n",
    "- The scale o the salesprice has changed drastically after transformation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets validate the integer and categorical columns and visualise them seperately using the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Features having integer and float datatype\n",
    "data2.select_dtypes(include=['int64','float64']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the numericla features\n",
    "len(data2.select_dtypes(include=['int64','float64']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the features having numerical datatype \n",
    "data2[data2.select_dtypes(include=['int64','float64']).columns].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the features having categorical datatype\n",
    "\n",
    "categorical_columns= data2.select_dtypes(include=['object']).columns\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Length of categirical columns in our dataset\n",
    "len(categorical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- In total we have 41 categorical columns lets visualise them to understand the count of categories present in them \n",
    "- In total we have 34 numerical fearures including Target feature which is in numerical format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets understand how SalePrice is varied for various categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reusable method for countplot\n",
    "\n",
    "def countplot(feature,rotation):\n",
    "    plt.title(feature,size=14,color='green')           # Prints the tite for the plot\n",
    "    sns.countplot(x=feature,data=data2)  # creates a countplot for the given categorical column\n",
    "    plt.xticks(rotation=90)              # x- axis labels are rotated with the user given degree value\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countplot for `MSSubClass`\n",
    "# The plot displays the categories present in the feature and its count\n",
    "\n",
    "countplot('MSSubClass',90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As shown above feature `MSSubClass` has multple categories and few categories like `1-STORY W/FINISHED ATTIC ALL AGES` has very less count in the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countplot for `MSZoning`,`Street`,`LotShape`,`LandCounter`,`Utilities` and `LotConfig` are shown below\n",
    "# The plot displays the categories present in the feature and its count\n",
    "\n",
    "plt.figure(figsize=(20,14))\n",
    "\n",
    "plt.subplot(2,3,1)\n",
    "countplot('MSZoning',90)\n",
    "\n",
    "plt.subplot(2,3,2)\n",
    "countplot('Street',90)\n",
    "\n",
    "\n",
    "plt.subplot(2,3,3)\n",
    "countplot('LotShape',90)\n",
    "\n",
    "plt.subplot(2,3,4)\n",
    "countplot('LandContour',90)\n",
    "\n",
    "plt.subplot(2,3,5)\n",
    "countplot('Utilities',90)\n",
    "\n",
    "\n",
    "plt.subplot(2,3,6)\n",
    "countplot('LotConfig',90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As shown above `Street`,`Utilities` and `LandContour` are highly skewed to a single category and considerng them in our model may not bring good results.\n",
    "- As shown above `MSZoning` has categories calledd `RH` and `C(all)` which we can consider as a seperate category called others since its presence is very less in the category\n",
    "- As shown above `LotConfig` has categories calledd `FR2` and `FR3` which we can consider as a seperate category called others since its presence is very less in the category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating as special category called `others` for the following features\n",
    "\n",
    "data2['MSZoning'].replace(['RH','C (all)'],'others',inplace=True)\n",
    "data2['LotConfig'].replace(['FR2','FR3'],'others',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets drop Street and Utilities colum since they are highly skewed to a single category and downt help in our analysis\n",
    "\n",
    "data2.drop(['Street','Utilities','LandContour'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- we have dropped few columns wth the reason mentioned above and few catgeories has been treated seperately as shown above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LandSlope', 'Neighborhood', 'Condition1','Condition2', 'BldgType', 'HouseStyle'.\n",
    "\n",
    "plt.figure(figsize=(20,18))\n",
    "\n",
    "plt.subplot(2,3,1)\n",
    "countplot('LandSlope',90)\n",
    "\n",
    "plt.subplot(2,3,2)\n",
    "countplot('Neighborhood',90)\n",
    "\n",
    "plt.subplot(2,3,3)\n",
    "countplot('Condition1',90)\n",
    "\n",
    "plt.subplot(2,3,4)\n",
    "countplot('Condition2',90)\n",
    "\n",
    "plt.subplot(2,3,5)\n",
    "countplot('BldgType',90)\n",
    "\n",
    "plt.subplot(2,3,6)\n",
    "countplot('HouseStyle',90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As shown above `LandSlope` and `Condition2` are highly skewed to a single category and considerng them in our model may not bring good results.\n",
    "- As shown above `Condition1` feature has categories called 'RRAe','PosA','RRNn','RRNe' which we can consider as a seperate category called `others` since its presence is very less in the category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['Condition1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['Condition1'].replace(['RRAe','PosA','RRNn','RRNe'],'others',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets drop condition2 column since it is highly skewed to a single category\n",
    "\n",
    "data2.drop(['LandSlope','Condition2'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- we have dropped few columns wth the reason that single category is biased in the categorical column few catgeories has been considered as `others` cateory which can be treated seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 'OverallQual', 'OverallCond','RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd'\n",
    "    \n",
    "    \n",
    "plt.figure(figsize=(20,14))\n",
    "\n",
    "plt.subplot(2,3,1)\n",
    "countplot('OverallQual',90)\n",
    "\n",
    "plt.subplot(2,3,2)\n",
    "countplot('OverallCond',90)\n",
    "\n",
    "plt.subplot(2,3,3)\n",
    "countplot('RoofStyle',90)\n",
    "\n",
    "plt.subplot(2,3,4)\n",
    "countplot('RoofMatl',90)\n",
    "\n",
    "plt.subplot(2,3,5)\n",
    "countplot('Exterior1st',90)\n",
    "\n",
    "plt.subplot(2,3,6)\n",
    "countplot('Exterior2nd',90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As shown above `RoofMatl`is highly skewed to a single category and considerng it in our model may not bring good results,so lets drop this fetaure.S lets drop them in the next steps.\n",
    "- As shown above `Exterior1st` feature has categories called 'BrkComm','Stone','AsphShn','CBlock','ImStucc' which we can consider as a seperate category called `others` since its presence is very less in the category.We need to do this because these low presence of categories in the data can mislead or bias the data\n",
    "- As shown above `Exterior2nd` feature has categories called 'ImStucc','BrkComm','Stone','AsphShn','CBlock','ImStucc' which we can consider as a seperate category called `others` since its presence is very less in the category.We need to do this because these low presence of categories in the data can mislead or bias the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['RoofStyle'].replace(['Flat','Gambrel','Mansard','Shed'],'others',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As shown above `RoofStyle` feature has categories called 'Flat','Gambrel','Mansard','Shed' which we can consider as a seperate category called `others` since its presence is very less in the category.We need to do this because these low presence of categories in the data can mislead or bias the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['Exterior1st'].replace(['BrkComm','Stone','AsphShn','CBlock','ImStucc'],'others',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['Exterior2nd'].replace(['ImStucc','BrkComm','Stone','AsphShn','CBlock','ImStucc'],'others',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.drop('RoofMatl',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- we have dropped few columns wth the reason that single category is biased in the categorical column few catgeories has been considered as `others` cateory which can be treated seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 'MasVnrType','ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond' \n",
    "    \n",
    "plt.figure(figsize=(20,14))\n",
    "\n",
    "plt.subplot(2,3,1)\n",
    "countplot('MasVnrType',90)\n",
    "\n",
    "plt.subplot(2,3,2)\n",
    "countplot('ExterQual',90)\n",
    "\n",
    "plt.subplot(2,3,3)\n",
    "countplot('ExterCond',90)\n",
    "\n",
    "plt.subplot(2,3,4)\n",
    "countplot('Foundation',90)\n",
    "\n",
    "plt.subplot(2,3,5)\n",
    "countplot('BsmtQual',90)\n",
    "\n",
    "plt.subplot(2,3,6)\n",
    "countplot('BsmtCond',90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As shown above `Foundation` feature has categories called 'Slab','Stone','Wood' which we can consider as a seperate category called `others` since its presence is very less in the category.We need to do this because these low presence of categories in the data can mislead or bias the data\n",
    "- Presenceof other categorical is not very biased so we havent considered any special tret=atment for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['Foundation'].replace(['Slab','Stone','Wood'],'others',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.drop(['BsmtCond','ExterCond'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- we have dropped few columns with the reason that single category is biased in the categorical column few catgeories has been considered as `others` cateory which can be treated seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " # 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC','CentralAir' \n",
    "\n",
    "plt.figure(figsize=(20,14))\n",
    "\n",
    "plt.subplot(2,3,1)\n",
    "countplot('BsmtExposure',90)\n",
    "\n",
    "plt.subplot(2,3,2)\n",
    "countplot('BsmtFinType1',90)\n",
    "\n",
    "plt.subplot(2,3,3)\n",
    "countplot('BsmtFinType2',90)\n",
    "\n",
    "plt.subplot(2,3,4)\n",
    "countplot('Heating',90)\n",
    "\n",
    "plt.subplot(2,3,5)\n",
    "countplot('HeatingQC',90)\n",
    "\n",
    "plt.subplot(2,3,6)\n",
    "countplot('CentralAir',90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['HeatingQC'].replace(['Fa','Po'],'others',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As shown above `HeatingQC` feature has categories called 'Fa','Po' which we can consider as a seperate category called `others` since its presence is very less in the category.We need to do this because these low presence of categories in the data can mislead or bias the data\n",
    "- Presenceof other categorical is not very biased so we havent considered any special tret=atment for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.drop(['Heating','CentralAir','BsmtFinType2'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- we have dropped few columns with the reason that single category is biased in the categorical column few catgeories has been considered as `others` cateory which can be treated seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Electrical', 'KitchenQual', 'Functional', 'GarageType' ,'GarageFinish', 'GarageQual',\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "plt.subplot(3,3,1)\n",
    "countplot('Electrical',90)\n",
    "\n",
    "plt.subplot(3,3,2)\n",
    "countplot('KitchenQual',90)\n",
    "\n",
    "plt.subplot(3,3,3)\n",
    "countplot('Functional',90)\n",
    "\n",
    "plt.subplot(3,3,4)\n",
    "countplot('GarageType',90)\n",
    "\n",
    "plt.subplot(3,3,5)\n",
    "countplot('GarageFinish',90)\n",
    "\n",
    "plt.subplot(3,3,6)\n",
    "countplot('GarageCond',90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As observed form the plots `Functional` feature has highly skewed data since majority of the data belongs to single category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cunt of different categories in `GarageType`\n",
    "data2['GarageType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['GarageType'].replace(['Basment','CarPort','2Types'],'others',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As shown above `GarageType` feature has categories called 'Basment','CarPort','2Types' which we can consider as a seperate category called `others` since its presence is very less in the category.We need to do this because these low presence of categories in the data can mislead or bias the data\n",
    "- Presenceof other categorical is not very biased so we havent considered any special treatment for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## As observed above itsbetter to drop the functional column\n",
    "\n",
    "data2.drop(['Electrical','Functional','GarageCond'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- we have dropped few columns with the reason that single category is biased in the categorical column few catgeories has been considered as `others` cateory which can be treated seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'PavedDrive', 'SaleType', 'SaleCondition'\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "countplot('PavedDrive',90)\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "countplot('SaleType',90)\n",
    "\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "countplot('SaleCondition',90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['SaleCondition'].replace(['Family','Alloca','AdjLand'],'Others',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As shown above `SaleCondition` feature has categories called 'Family','Alloca','AdjLand' which we can consider as a seperate category called `others` since its presence is very less in the category.We need to do this because these low presence of categories in the data can mislead or bias the data\n",
    "- Presence of other categorical is not very biased so we havent considered any special treatment for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets drop the below columns/features since we have very less count for other categories and Category: WD is highly occuring in this column\n",
    "\n",
    "data2.drop('SaleType',axis=1,inplace=True)\n",
    "data2.drop('PavedDrive',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As shown above we have dropped few columns with the reason that single category is biased in the categorical column few catgeories has been considered as `others` cateory which can be treated seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical columns\n",
    "\n",
    "categorical_columns= data2.select_dtypes(include=['object']).columns\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(categorical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As shown above now we have 25 categorical columns earlier the count was 41 since we dropped some categorical columns we are left with 25.\n",
    "- The reason behind dropping of some categorical columns has been mentioned in the abive steps where the presence of single catgeory in the categorical column tell the same info to the model, Considering his we have dropped fewof the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets see the relation between categorical columns and  SalesPrice using BoxPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reusable method to create the box plot in finding the relation between categorical column and Saleprice(Target) column\n",
    "def boxplot(inputfeature,rotation):\n",
    "    plt.title(inputfeature+' v/s SalePrice',size=15,color='green')\n",
    "    sns.boxplot(x=inputfeature,y='SalePrice',data=data2)\n",
    "    plt.xticks(rotation=rotation)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "boxplot('MSSubClass',45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- A s shown above feature `MsSubClass` has many categories and its showing the good relation with Saleprice(target) column\n",
    "- we could see that sale price is more when  categories fall under this categories: `2-STORY 1946 & NEWER` and `1-STORY 1946 & NEWER ALL STYLES`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #  Box plot for `Sale Price versus 'MSZoning', 'LotShape', 'LotConfig', 'Neighborhood','Condition1', 'BldgType',\n",
    "plt.figure(figsize=(20,25))\n",
    "\n",
    "plt.subplot(3,3,1)\n",
    "boxplot('MSZoning',90)\n",
    "\n",
    "plt.subplot(3,3,2)\n",
    "boxplot('LotShape',90)\n",
    "\n",
    "plt.subplot(3,3,3)\n",
    "boxplot('LotConfig',90)\n",
    "\n",
    "plt.subplot(3,3,4)\n",
    "boxplot('Neighborhood',90)\n",
    "\n",
    "plt.subplot(3,3,5)\n",
    "boxplot('Condition1',90)\n",
    "\n",
    "plt.subplot(3,3,6)\n",
    "boxplot('BldgType',90)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As shown above we have plotted  `Sale Price` versus `MSZoning`,`LotShape`,`LotConfig`,`Neighborhood`,`Condition1`,`BldgType`. We may get good information from these features and can obtain best results in predicting the Saleprice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #  Box plot for `Sale Price` versus 'HouseStyle', 'OverallQual', 'OverallCond','RoofStyle', 'Exterior1st', 'Exterior2nd'\n",
    "plt.figure(figsize=(20,28))\n",
    "\n",
    "plt.subplot(3,3,1)\n",
    "boxplot('HouseStyle',90)\n",
    "\n",
    "plt.subplot(3,3,2)\n",
    "boxplot('OverallQual',90)\n",
    "\n",
    "plt.subplot(3,3,3)\n",
    "boxplot('OverallCond',90)\n",
    "\n",
    "plt.subplot(3,3,4)\n",
    "boxplot('RoofStyle',90)\n",
    "\n",
    "plt.subplot(3,3,5)\n",
    "boxplot('Exterior1st',90)\n",
    "\n",
    "plt.subplot(3,3,6)\n",
    "boxplot('Exterior2nd',90)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As shown above we have plotted  `Sale Price` versus 'HouseStyle', 'OverallQual', 'OverallCond','RoofStyle', 'Exterior1st', 'Exterior2nd'.\n",
    "- RoofStyle median looks somethings suspicious has outliers as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #  Box plot for `Sale Price` versus 'MasVnrType', 'ExterQual','Foundation', 'BsmtQual', 'BsmtExposure', 'BsmtFinType1'\n",
    "\n",
    "plt.figure(figsize=(20,25))\n",
    "\n",
    "plt.subplot(3,3,1)\n",
    "boxplot('MasVnrType',90)\n",
    "\n",
    "plt.subplot(3,3,2)\n",
    "boxplot('ExterQual',90)\n",
    "\n",
    "plt.subplot(3,3,3)\n",
    "boxplot('Foundation',90)\n",
    "\n",
    "plt.subplot(3,3,4)\n",
    "boxplot('BsmtQual',90)\n",
    "\n",
    "plt.subplot(3,3,5)\n",
    "boxplot('BsmtExposure',90)\n",
    "\n",
    "plt.subplot(3,3,6)\n",
    "boxplot('BsmtFinType1',90)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As shown above we have plotted `Sale Price` versus 'MasVnrType', 'ExterQual','Foundation', 'BsmtQual', 'BsmtExposure', 'BsmtFinType1'\n",
    "\n",
    "- We have many outliers as sown above but lets not treat this at this stage.And we cannot say that these are complete outliers since we are dealing with categorical versus numerical multiple catgeories can impact the target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #  Box plot for `Sale Price` versus 'HeatingQC','KitchenQual', 'GarageType', 'GarageFinish', 'GarageQual','SaleCondition'\n",
    "plt.figure(figsize=(20,28))\n",
    "\n",
    "plt.subplot(3,3,1)\n",
    "boxplot('HeatingQC',90)\n",
    "\n",
    "plt.subplot(3,3,2)\n",
    "boxplot('KitchenQual',90)\n",
    "\n",
    "plt.subplot(3,3,3)\n",
    "boxplot('GarageType',90)\n",
    "\n",
    "plt.subplot(3,3,4)\n",
    "boxplot('GarageFinish',90)\n",
    "\n",
    "plt.subplot(3,3,5)\n",
    "boxplot('GarageQual',90)\n",
    "\n",
    "plt.subplot(3,3,6)\n",
    "boxplot('SaleCondition',90)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As shown above we have plotted `Sale Price` versus 'HeatingQC','KitchenQual', 'GarageType', 'GarageFinish', 'GarageQual','SaleCondition'\n",
    "- We have many outliers as shown above but lets not treat this at this stage.And we cannot say that these are complete outliers since we are dealing with categorical versus numerical multiple catgeories can impact the target column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets visualise and treat numerical columns if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.select_dtypes(include=['int64','float64']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data2.select_dtypes(include=['int64','float64']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.select_dtypes(include=['int64','float64']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- In total we have 34 columns conatining datatype as `integer` and `float`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data2['YearBuilt'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- `YearBuilt` says the original construction year of the building\n",
    "- As shown above `YearBuilt` feature has left skewed data and its not complete normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data2['YearRemodAdd'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- `YearRemodAdd` says the original construction year of the building\n",
    "- As shown above `YearRemodAdd` feature has skewed data and its not complete normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Extract features`: Lets create a new features called `Remodelledyearsback` and `AgeOfBuilding` which tells how many years back building was constructed and how many years back building was reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets add a feature called `Remodelledyearsback` which tells how many years remodel has been done for the building\n",
    "\n",
    "data2['Remodelledyearsback']=2021-data['YearRemodAdd']\n",
    "data2['Remodelledyearsback']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets add a feature called `AgeOfBuilding` which tells how many years back building was constructed\n",
    "data2['AgeOfBuilding']=2021-data['YearBuilt']\n",
    "data2['AgeOfBuilding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data2['AgeOfBuilding'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- Age of buiding is right skewed but the scale is better than`YearBuilt`\n",
    "- As we know the AgeOfBuilding plays a key role in the price of the building.Lets take this varibale forward and do some modelling by considering this varibale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.drop(['YearBuilt','YearRemodAdd'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- Lets drop `YearBuilt` and `YearRemodAdd` since we have created new columns which indicates how old the buildings are from 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data2['SalePrice']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.drop('SalePrice',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation:\n",
    "- As shown in the above two steps we have created a target variable(y) which is a `SalePrice` y and removed the same from data2 dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the top 5 rows of dataframe\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displying the features having numerical(int and float) datatype \n",
    "data2.select_dtypes(include=['int64','float64']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Column Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets treat the categorical columns\n",
    "\n",
    "CategoricalColumns=data2.select_dtypes(include=['object'])\n",
    "CategoricalColumns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Display all the categorical columns\n",
    "\n",
    "CategoricalColumns.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CategoricalColumns stores dataframe of categorical columns obtained from data2\n",
    "CategoricalColumns=data2[CategoricalColumns.columns]\n",
    "CategoricalColumns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As shown above `CategoricalColumns` stores dataframe containing the features having datatype of categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CategoricalColumns2 stores dataframe after converting categorical column into integer format\n",
    "CategoricalColumns2=pd.get_dummies(CategoricalColumns,drop_first=True)\n",
    "CategoricalColumns2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "- We have used `CategoricalColumns2` for storing dataframe after converting catgeries to numerical representation\n",
    "- As shown above we have used get_dummies to convert categorical columns to numerical so that we can fit the data to the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CategoricalColumns2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop original categroical columns since we created new ones using get_dummies\n",
    "data2.drop(CategoricalColumns.columns,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- We have dropped our categorical columns from original dataframe `data2` and all the categorical column are stored in `CategoricalColumns2` after treating them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As shown above we have 33 features which are numerical in nature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe called `newdf` which is a combination of numerical fetures and Categorical columns after the treatment\n",
    "newdf=pd.concat([data2,CategoricalColumns2],axis=1)\n",
    "newdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- In the previous steps we have obtained the dataframe which is suitable for model building so all the input features for our model is stored in the following variable`newdf`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Train_Test_Split for Training and evalating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(newdf,y,train_size=0.75,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let initialise the standard scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As shown above all the column/feature names are displayed where datatype of the feature is integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply standard scaling on numerical column\n",
    "x_train[data2.columns]=sc.fit_transform(x_train[data2.columns])\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As shown above the features are applied with standard scaling which are numerical in nature\n",
    "- We didnt make any changes to the features where we have conveted categories to numerical representation using get_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test[data2.columns]=sc.transform(x_test[data2.columns])\n",
    "x_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As shown above we have applied transform on the test data for applying standard scaling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries which helps for Recursive feature elimination\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialis Linear regression \n",
    "lr=LinearRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "\n",
    "# Select Top 50 features using recursive feature elimination technique\n",
    "rfe=RFE(lr,50)\n",
    "rfe=rfe.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As shown above we have taken 50 top features which are best for our model building process using recursive feature elimination.\n",
    "\n",
    "- The approach is taken, to reduce overall column count to th model since earlier we have 181 features since we had lot of categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets display the column names,support and ranking of the selected features after applying RFE\n",
    "list(zip(x_train.columns,rfe.support_,rfe.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a variable called `newcol` which holds feature names of all the top 50 selected features\n",
    "newcol=x_train.columns[rfe.support_]\n",
    "newcol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As shown above we have obtained the best 50 features which can be fitted with lasso and ridge regression models\n",
    "- Now we have obtained best features after applying recursive feature elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train[newcol]\n",
    "x_test=x_test[newcol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As shown above we have assigned new feature names for the x_train and x_test variables\n",
    "- Split of training and test is as expected with rows and columns also as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Ridge and Lasso Regression models\n",
    "from sklearn.linear_model import Lasso,Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Grid search Cv\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create params which is alpha in our case and passed to our GridsearchCV which creates multiple folds.\n",
    "params={'alpha':[0.0001,0.001,0.01,0.05,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.,8,0.9,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,50,100,100]}\n",
    "ridge=Ridge()   #Initisalising Ridge\n",
    "folds=5  # Number of folds\n",
    "ridgemodel=GridSearchCV(estimator=ridge,  #estimator here is ridge\n",
    "                     param_grid=params,\n",
    "                     cv=folds,\n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     return_train_score=True,\n",
    "                     verbose=1)\n",
    "ridgemodel.fit(x_train,y_train)  # Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ilter bet params value for our model which is best alpha in this case\n",
    "ridgemodel.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As shown in the previous two steps we have applied Gridsearch with ridge estimator and obtained 135 fits.\n",
    "- We have obtained best alpha value as 4.0,Lets fit and train the model with this alpha value in next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets fit the model with the alpha value 6\n",
    "alpha=6.0,\n",
    "ridge=Ridge(alpha=alpha)\n",
    "ridge.fit(x_train,y_train)\n",
    "print(ridge.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RidgeCoeff=pd.DataFrame(index=x_train.columns,data=sorted(ridge.coef_,reverse=True),columns=['Coef'])\n",
    "RidgeCoeff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As shown above all the coefficient values are shown along with its features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- Train and Test results wth Ridge Reression\n",
    "    - Training score: 0.87\n",
    "    - Test score    : 0.87"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Top 5 features using Ridge\n",
    "RidgeCoeff.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets crete params which is alpha in our case and passed to our GridsearchCV model which creates multiple folds.\n",
    "params={'alpha':[0.0001,0.001,0.01,0.05,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.,8,0.9,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,50,100,100]}\n",
    "lasso=Lasso()   #Initialising Lasso \n",
    "folds=5   #Number of folds\n",
    "lassomodel=GridSearchCV(estimator=lasso,   #estimator here is lasso\n",
    "                     param_grid=params,\n",
    "                     cv=folds,\n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     return_train_score=True,\n",
    "                     verbose=1)\n",
    "lassomodel.fit(x_train,y_train)  # fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the best params value for alpha\n",
    "lassomodel.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As shown in the previous two steps we have applied Gridsearch with Lassos estimator and obtained 135 fits.\n",
    "- We have obtained best alpha value as 0.001,Lets fit and train the model with this alpha value in next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Lets fit the model with the alpha value 0.001\n",
    "alpha=0.001,\n",
    "lasso=Lasso(alpha=alpha)\n",
    "lasso.fit(x_train,y_train)\n",
    "print(lasso.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LassoCoeff=pd.DataFrame(index=x_train.columns,data=sorted(lasso.coef_,reverse=True),columns=['Coef'])\n",
    "LassoCoeff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As shown above all the coefficient values are shown along with its features.\n",
    "- We could see that coefficient values are 0 for variables like `Condition1_Norm`, `Condition1_RRAn`, `BldgType_Twnhs`,`OverallQual_Average`,`OverallQual_Below Average`,`OverallQual_Excellent`,`OverallQual_Fair`,`OverallQual_Good`,`OverallQual_Poor`,`OverallQual_Very Good` indicating less significance in preddicting the house prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- Train and Test results wth Lasso Reression\n",
    "    - Training score: 0.866\n",
    "    - Test score    : 0.87"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Top 5 features using lasso\n",
    "LassoCoeff.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of the Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Value for Ridge and Lasso:\n",
    "\n",
    "    - Optimal lambda value for Ridge : 6.0\n",
    "    - Optimal lambda value for lasso : 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables significant in preicting the price of the house using Ridge Regression are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RidgeCoeff.head(5)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables significant in predicting the price of the house using Lasso Regression are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LassoCoeff.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics obtained using ridge and Lasso:\n",
    "- Ridge regression:\n",
    "    - Training: 0.87\n",
    "    - Testing: 0.87\n",
    "- lasso regression:\n",
    "    - Training: 0.866\n",
    "    - Testing:  0.87"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From both Ridge and Lasso Below variables shows strong Predictors in making predictions of houses, So company can concentrate on this variables :\n",
    "- GrLivArea\n",
    "- AgeOfBuilding\n",
    "- MSSubClass_1-STORY 1946 & NEWER ALL STYLES\n",
    "- MSSubClass_2-STORY PUD - 1946 & NEWER\n",
    "- MSSubClass_PUD - MULTILEVEL - INCL SPLIT LEV/FOYER"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
