{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Reading the country-data.csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Read the csv file and print first 5 rows of the file\n",
    "data=pd.read_csv('Country-data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying the number of rows and columns in the data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation:\n",
    "\n",
    "   - We have 167 rows and 10 columns in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying data types and non-Null value count of all columns\n",
    "data.info()         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insights:\n",
    "   - Income and gdpp is in integer format which is as expected,Column country is in Object format which is as ecpected.\n",
    "   - Columns: child_mort,exports,health,imports,inflation,life_expec and total_fer is in float format which is as expected.\n",
    "   - Datatype of all columns is as expected,Datatype handling is not required for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistical Summary of the dataset\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inspecting Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify null value count for all columns\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation:\n",
    "\n",
    "   - We have 0 Null values in all the columns.SO Null value treatment is not required for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert columns/features: exports,health and imports to their original values, Since the data given is percentage of the GDP per capita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert columns/features: exports,health and imports to their original values \n",
    "data['exports']=data['gdpp']/data['exports']\n",
    "data['health']=data['gdpp']/data['health']\n",
    "data['imports']=data['gdpp']/data['imports']\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "   - Since the following features : `exports`, `health` and `imports` are given in the form of percenatge of GDP we have converted to their original values in the above step which will help for further analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Value Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets validate that we dont have negative values in the data.Negative values in the data may indicate the false data in some of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['child_mort']<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['exports']<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['health']<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['imports']<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['income']<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['life_expec']<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['total_fer']<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['gdpp']<0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "   - We dont have negative values for the features `child_mort`,`exports`,`health`,`imports`,`income`,`life_expec`,`total_fer` and `gdpp`, which is good sign we can go ahead with further steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['inflation']<0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - Some countries have Negative inflaton which is possible actually. So lets not remove them at this point of analysis.   We can treat them in further analysis if required.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reusable method for performing univariate analysis\n",
    "\n",
    "def univ_anal(col_name):  # Pass feature name for making Box plot.\n",
    "    plt.title('Data Distribution of '+ col_name+ ' column',size=15,color='green')\n",
    "    sns.boxplot(y=data[col_name])    # Box plot can be drawn for the given feature.\n",
    "    plt.ylabel(col_name,size=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot for child_mort\n",
    "univ_anal('child_mort')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insights:\n",
    "\n",
    "   - As observed child mortality tells us how many deaths out of 1000 children  in a country.We have few observations where child mortality rate is greater than 150 which is a serious consideration in our outcome.\n",
    "   - High child_mort indicates countries which may indicate poor countries,lets consider this feature for further analysis.\n",
    "   - This feature is strong indicator  who are required in help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univ_anal('exports')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - exports indicates exporting of goods and services. We could see that their are outliers.\n",
    "   - Let's cap this exports column which will help in avoiding skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "univ_anal('health')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - As shown in the above boxplot `health` feature has outlier at the value near 40000 which look suspicious.Lets cap them at 0.95 percentile in further steps after analysing the distribution plot as well.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "univ_anal('imports')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "    \n",
    "   - As shown in the above boxplot `imports` feature has outlier near 14000 which is max value and it look suspicious. Lets cap them at 0.95 percentile\n",
    "   -We also Noticed that there are huge set of values above 75th percentile.Since we have less data dropping them result in loss of data.Lets cap them at 0.95th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univ_anal('income')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insights:\n",
    "\n",
    "   - As observed column income has huge set of outliers are visible in this feature.Lets cap them at 0.95\n",
    "   - Column `income` has an outlier which looks suspicious at greater than 120000 let treat these values as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univ_anal('inflation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - As observed in the above box plot.We have outliers near 100 which looks suspicious.But there is a possibility of some countries having higher inflation.So lets not remove them.We will verify the distribution as well to better understand the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univ_anal('life_expec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - `life_expec`has some lower values near 32. And we have few more outliers near 46.Lets see the distribution plot and cap the outliers if required in the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univ_anal('total_fer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - `total_fer` column has some good spread of data and nothing suspicious other than value near 7. Lets analyse the distribution of data and lets treat the outlier if required.\n",
    "   - Value near 7 has a possibilty in fertility. so lets understand in further plots to treat if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univ_anal('gdpp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - `gdpp` column is having some good amount of outliers.Lets understand the percentile values and cap them in further steps after verifying the distribution plot for the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand the distribution of data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data['child_mort'])\n",
    "plt.title('Distribution plot for child_mort',size=15,color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - As shown above `child_mort` feature is right skewed. Which is quite common since some countries have the possibilty of this type of numbers which are high in child_mort.\n",
    "   - `child_mort` feature gives good insights in finding the countries which require help from orphanages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data['exports'])\n",
    "plt.title('Distribution plot for exports',size=15,color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - As shown above `exports` feature is right skewed. Which is quite common since some countries have the highest exports due to highly developed manufacturing and farming capabilities and many other reasons can make the countries exports high  \n",
    "   - `exports` feature has right skewed data considering this may affect the model's perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data['health'])\n",
    "plt.title('Distribution plot for health',size=15,color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - As shown above `health` feature is right skewed, considering this may affect the model's perfomance lets cap the feature to 0.95 in further steps\n",
    "   - Capping the outlier is the best option since we have less data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data['imports'])\n",
    "plt.title('Distribution plot for imports',size=15,color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - As shown above `imports` feature is right skewed. Which is quite common since some countries has less farming lands,Industries and raw materials,Due to which these countries relay on imports  \n",
    "   - `imports` feature has right skewed data considering this may affect the model's perfomance,lets cap the outliers in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data['income'])\n",
    "plt.title('Distribution plot for income',size=15,color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - `income` feature says about net income of the person in the country\n",
    "   - As shown above `income` feature is right skewed. Which is quite common since some countries has less jobs due to which many of the citizens will be unemployed  \n",
    "   - `income` feature has right skewed data considering this may affect the model's perfomance,lets cap the outliers in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data['inflation'])\n",
    "plt.title('Distribution plot for inflation',size=15,color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "   - `inflation` is all about the measurement of the annual growth rate of the Total GDP \n",
    "   - As shown above `inflation` feature is right skewed.When inflation gets higher,economic growth will decelerate resulting in cost of living drastically changes\n",
    "   - This is one of the strong indicator for people required aid due to cost of living is very high when inflation is high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data['life_expec'])\n",
    "plt.title('Distribution plot for life_expec',size=15,color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - `life_expec` feature says about the average number of years a new born child would live if the current mortality patterns are to remain the same\n",
    "   - As shown above `life_expec` feature is left skewed.Average human life expectancy for some counries looks weird we need to treat the left skewed data where outliers are present,Lets cap the outliers in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data['total_fer'])\n",
    "plt.title('Distribution plot for total_fer',size=15,color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - `total_fer` feature says about the the number of children that would be born to each woman if the current age-fertility rates remain the same.\n",
    "\n",
    "   - As shown above `total_fer` feature is right skewed very slightly.Which doesn't require any outlier treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data['gdpp'])\n",
    "plt.title('Distribution plot for gdpp',size=15,color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - `gdpp` feature says about the GDP per capita. Calculated as the Total GDP divided by the total population.\n",
    "   - As shown above `gdpp` feature is right skewed. Which is quite common since some developed countries have high GDP.\n",
    "   - Majority of the countries have GDP less than 10000\n",
    "   - `gdpp` feature has right skewed data considering this may affect the model's perfomance,lets cap the outliers in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capping outlier: Since we have less data we are capping the data instead of dropping the outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are not capping some of the features because of the following reason:\n",
    "\n",
    "  - `life_expec` is not heavily skewed.so we are not treating outliers in this feature.\n",
    "  \n",
    "  - `child_mort` tells the needs of aid. so there may be countries which are very high in number in child_mort which might be true need and lets not drop or cap the outliers here\n",
    "  - `total_fer` is not heavily skewed as observed in the above plots so no treatment of outlier is required\n",
    "  - `inflation` has some negative values and not hevaily skewed in the positive range. So we are not cappping them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets Treat the columns which are highly skewed,Lets cap the outliers which are less than 0.05 percentile and greater than 0.95 percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split1 hold feature names which helps in capping the outliers\n",
    "\n",
    "split1=['exports','health','imports','income','gdpp']\n",
    "len_split1=len(split1)  # length/count of the features\n",
    "\n",
    "plt.figure(figsize=(14,10))\n",
    "\n",
    "print('Distribution of Features before perfroming capping on outliers')\n",
    "for i,j in zip(split1,range(len_split1)): \n",
    "    plt.subplot(3,2,j+1)\n",
    "    sns.distplot(data[i])   # Distribution plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - Above plot shows the distribution of features `exports`, `health`,`imports`,`income` and `gdpp` before perfoming capping to treat outliers.\n",
    "   - Insights of each column/feature we are considering here is already explained in previous steps where we studied about distribution of plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look for different percentile values before capping the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split1 hold feature names which helps in capping the outliers\n",
    "\n",
    "split1=['exports','health','imports','income','gdpp']\n",
    "len_split1=len(split1)\n",
    "print('Percentile values before capping the outliers\\n')\n",
    "for i,j in zip(split1,range(len_split1)):\n",
    "    print('Percentile values before capping the outliers for '+ i +' is :\\n', data[i].quantile([0,0.05,0.1,0.9,0.95,0.99,1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - In the above step we analysed the different percentiles like (0.05,0.95,1) features `exports`, `health`,`imports`,`income` and `gdpp` before perfoming capping to treat outliers.\n",
    "   - Lets cap the data for the following features `exports`, `health`,`imports`,`income` and `gdpp` at 0.05 for percentiles having less than 0.05 and 0.95 for percentiles having greater than 0.95 percentiles "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform capping on the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split1 hold feature names which helps in capping the outliers\n",
    "\n",
    "split1=['exports','health','imports','income','gdpp']\n",
    "len_split1=len(split1)\n",
    "\n",
    "for i,j in zip(split1,range(len_split1)):\n",
    "    percentilevalues = data[i].quantile([0.05,0.95]).values\n",
    "    data[i] = np.clip(data[i], percentilevalues[0], percentilevalues[1])  # Replace the original features after capping the data \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - In the above step we have capped the outliers for the following features `exports`, `health`,`imports`,`income` and `gdpp` \n",
    "   - Lets see the distribution plot to analyse how the skewness has been changed after this step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split1=['exports','health','imports','income']\n",
    "len_split1=len(split1)\n",
    "\n",
    "print('Percentile values After capping the outliers\\n')\n",
    "for i,j in zip(split1,range(len_split1)):\n",
    "    print('percentile values After applying capping for '+ i +' is :\\n', data[i].quantile([0,0.05,0.1,0.9,0.95,0.99,1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - In the above step we analysed the different percentiles like (0.05,0.95,1) features `exports`, `health`,`imports`,`income` and `gdpp` After perfoming capping to treat outliers.\n",
    "   - capping has been in the following way values less than 0.05 percentile has been capped to 0.05 percentile value,Values greater than 0.95 has been capped to 0.95 th percentile value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split1 hold feature names which helps in capping the outliers\n",
    "\n",
    "split1=['exports','health','imports','income','gdpp']\n",
    "len_split1=len(split1)  # length/count of the features\n",
    "\n",
    "plt.figure(figsize=(14,10))\n",
    "\n",
    "print('Distribution of Features After perfroming capping on outliers')\n",
    "for i,j in zip(split1,range(len_split1)): \n",
    "    plt.subplot(3,2,j+1)\n",
    "    sns.distplot(data[i])   # Distribution plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - Now the skewness of the data has been reduced, Which is good for building the clusters\n",
    "   - Majority of the skewed data has been treated now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.Bivariate  and Multivariate Analyssis\n",
    "\n",
    "## Numeric - Numeric analysis\n",
    "\n",
    "- There are three ways to analyse the *`numeric- numeric`* data types simultaneously.\n",
    "- **Scatter plot**: describes the pattern that how one variable is varying with other variable.\n",
    "- **Correlation matrix**: to describe the linearity of two numeric variables.\n",
    "- **Pair plot**: group of scatter plots of all numeric variables in the data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets visualise the correlation between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data.iloc[:,1:].corr(),cmap='gray',cbar=True,annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - As shown above we have plotted correlation values using heatmap.which helps in further understanding which variables are highly correlated\n",
    "   - Lets see the top correlated variables in the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top correlated variables\n",
    "data.corr().abs().unstack().sort_values(ascending= False)[9:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - As shown above we have arrived at features having high correlation values\n",
    "   - `income` and `health` has highest correlation among all the features\n",
    "   - `income` and `gdpp` has the second highest correlation with the value of 0.94151\n",
    "   - `imports` and `exports` has the third highest correlation with the correlation value of 0.933"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reusable method for bivariate analysis\n",
    "def bi_anal(feature1,feature2):\n",
    "    plt.title('Data Distribution of '+ feature1+ ' versus ' + feature2,size=15,color='green')\n",
    "    sns.scatterplot(feature1,feature2,data=data)\n",
    "    plt.xlabel(feature1,size=12)\n",
    "    plt.ylabel(feature2,size=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_anal('income','gdpp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - As shown in the above plot `gdpp` and `income` has highest correlation as the income increases gdpp also increases linearly\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_anal('income','health')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - As we have seen in the correlation matrix we have high correlation values for `income` and `health`,We could see that as the average income of the person increases Total health spending also increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_anal('imports','exports')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - As we have seen in the correlation matrix we have high correlation values for `imports` and `exports`.\n",
    "   - There is a equal chances for countries to have higher import and export values since all the countries might not be     good in all the goods and due to lack of resources there is a goods exchange tackes place between countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_anal('total_fer','child_mort')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "   - `total_fer` tells about the number of children that would be born to each woman if the current age-fertility rates remain the same. \n",
    "   - As the `total_fer` increase `child_mort` increases this is quite obvious since both the varibales are positively correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bi_anal('health','child_mort')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - From the above plot we could understand that when the `health`(Total health spending per capita) increase child_mort decreases.\n",
    "   - Less spending of `health` Increase in `child_mort`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_anal('health','gdpp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "  - Feature `health` tells about the Total health spending per capita.\n",
    "  - We can consider high GDP for developed countries where usually the average income and health spending will increase,Due to which we can see health and GP is correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_anal('child_mort','life_expec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - As we can see when `life_expec` is high `child_mort` is low which is quite obvious since child_mort tells about the Death of children under 5 years of age per 1000 live births.\n",
    "   - So both the variables are negatively correlated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_anal('imports','gdpp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "    - GDP and imports are linearly related when the imports are at lower range GDP is also low.\n",
    "    - As the imports increases GDP also increases linearly.\n",
    "    - But we need to consider multiple factors when calclulating GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_anal('life_expec','total_fer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "  - we could that the life_expec is more when the ferility is less but we cannot conclude anything since the data we have has high range of life_expec values and total_fer value is high between 1to 5 as we observed in the total_fer box plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe data1 which holds features other than country column\n",
    "data1=data.iloc[:,1:]\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.Hopkins Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hopkins analysis to understand how well our data is suitable for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the Hopkins statistic\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from random import sample\n",
    "from numpy.random import uniform\n",
    "from math import isnan\n",
    " \n",
    "def hopkins(X):\n",
    "    d = X.shape[1]\n",
    "    n = len(X) # rows\n",
    "    m = int(0.1 * n) \n",
    "    nbrs = NearestNeighbors(n_neighbors=1).fit(X.values) \n",
    "    rand_X = sample(range(0, n, 1), m) \n",
    "    ujd = []\n",
    "    wjd = []\n",
    "    for j in range(0, m):\n",
    "        u_dist, _ = nbrs.kneighbors(uniform(np.amin(X,axis=0),np.amax(X,axis=0),d).reshape(1, -1), 2, return_distance=True)\n",
    "        ujd.append(u_dist[0][1])\n",
    "        w_dist, _ = nbrs.kneighbors(X.iloc[rand_X[j]].values.reshape(1, -1), 2, return_distance=True)\n",
    "        wjd.append(w_dist[0][1]) \n",
    "    HO = sum(ujd) / (sum(ujd) + sum(wjd))\n",
    "    if isnan(HO):\n",
    "        print(ujd, wjd)\n",
    "        HO = 0\n",
    " \n",
    "    return HO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify hopkins value 10 times/multiple times to make sure our data is well suited for clustering\n",
    "for i in range(10):\n",
    "    print(hopkins(data1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - We are considering all the columns and lets see how Hopkins analysis say about how well data is suitable for clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets analyse the features:  `child_mort`,`gdpp` and `income` and form clusters using these features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe data2 which holds following features: gdpp,child_mortality and income\n",
    "data2=data[['gdpp','child_mort','income']]\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# verify hopkins value 10 times/multiple times to make sure our data is well suited for clustering\n",
    "for i in range(10):\n",
    "    print(hopkins(data2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - Value of Hopkins is always greater than 0.85 even after executing 10 times, which is strong indicator that data is suitable for cluster formation\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data2.corr(),cmap='gray',cbar=True,annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - As observed in the above heatmap we have high correlation at 0.94 between `gdpp` and `income` feature\n",
    "   - `child_mort` and `income` features have a high correlation value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing minmax scaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mm=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Filter country column\n",
    "country=data.iloc[:,:1]\n",
    "country.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.Finding optimal k value for kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FInding optimal k value with within cluster sum of squares method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import KMeans\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal cluster identification using within cluster sum of squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wcss=[]  # wcss is a empty list indicates within cluster sum of squares\n",
    "k=range(1,15)\n",
    "for i in k:\n",
    "    kmeans=KMeans(i,random_state=42)\n",
    "    kmeans.fit(data2)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "print(wcss)\n",
    "plt.plot(k,wcss)                                                      #plot the diagram in the form of x and y \n",
    "plt.title(\"Find optimal k value\")\n",
    "plt.xlabel(\"k value\")\n",
    "plt.ylabel(\"wcss value : within cluster sum of squares\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - As we can see at value k=3 and k=2 looks we have optimal value of k\n",
    "   - using this k value lets analyse the spread of data explained by clustersand decide the better k value for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that the data2 has only three columns before applying clustering on that\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `K=2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fithe data with k=2 clusters\n",
    "kmeans=KMeans(2,random_state=42)\n",
    "kmeans.fit(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - We have taken 2 clusters and data has been fitted on that lets see the cluster count across the data in next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stire the cluster labels in the variable y_kmeans\n",
    "y_kmeans=kmeans.fit_predict(data2)\n",
    "y_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the cluster column to the dataframe : data2\n",
    "data2['cluster']=y_kmeans\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - We have added cluster labels in the previous step to the dataframe data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.cluster.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - cluster 0 count is 128 and cluster 1 count is 39.\n",
    "   - Cluster 0 is having many data points we can go for other cluster value which is k=3 and see if that can explain the datapoints better than this cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets remove the cluster column from data2 before fitting the data2 to kmeans algorithm\n",
    "data2=data2.iloc[:,:-1]\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `K=3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fithe data with k=3 clusters\n",
    "kmeans=KMeans(3,random_state=42)\n",
    "kmeans.fit(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - We have taken 3 clusters and data has been fitted on that lets see the cluster count across the data in next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stire the cluster labels in the variable y_kmeans\n",
    "y_kmeans=kmeans.fit_predict(data2)\n",
    "y_kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - As shown above we have got the cluster number to which each row of the data belong to.Lets add this cluster value to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the cluster column to the dataframe : data2\n",
    "data2['cluster']=y_kmeans\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.cluster.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - cluster 0 count is 96,cluster 1 count is 40 and cluster2 count is 31.\n",
    "   - It looks when we considered k=3 clusters are explaining the data very well and data is not biased to a single cluster. So lets consider k value as 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster centers\n",
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "   - Cluster center values are displyed in the above step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the cluster column to the dataframe : data2\n",
    "data2['cluster']=y_kmeans\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the country column to the dataframe : data2\n",
    "data2['country']=data['country']\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - In the above two steps we have added country and cluster lables to the dataframe data3 which helps in further steps in identifying which country falls under which cluster group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before visualising the cluster lets find the optimal k value using Silhouette analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Silhouette Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal value of k can be obtained using silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling\n",
    "# Create new dataframe data3  with features: gdpp, child_mort and income and apply minmax scaler\n",
    "data2_columns=data2.iloc[:,:-2].columns\n",
    "data3=pd.DataFrame(mm.fit_transform(data2.iloc[:,:-2]),columns=data2_columns)\n",
    "data3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "    - Minmax scaling has been applied on the following features: `gdpp`,`child_mort` and `income`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#silhouette_score for finding optimal value of k \n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#silhoutee_avg=[]\n",
    "#k=range(1,10)\n",
    "range_clusters=[2,3,4,5,6,7,8]\n",
    "for i in range_clusters:\n",
    "    kmeans=KMeans(i,random_state=42)\n",
    "    kmeans.fit(data3)\n",
    "    cluster_labels=kmeans.labels_\n",
    "    silhouette=silhouette_score(data3,cluster_labels)\n",
    "    print(silhouette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the cluster centers(Centroids)\n",
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster labels tells to which cluster the data point belongs  to\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Insights:\n",
    "\n",
    "   - As observed in the above analysis we have better silhouette score when k=2: 0.65 and k=3: 0.52\n",
    "   - As we already observed the k value using ssd tells the same analysis but we saw better distribution of clusters when  k=3 in the above step. Lets consider k=3 as optimal calue and visualize the spread of clusters.       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After verifying k values at 2 and 3 data is well explained when k=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets visualise the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = 'income', y ='child_mort', hue = 'cluster', data =data2,palette=['blue','green','red'])\n",
    "plt.xlabel('income',fontsize=13)\n",
    "plt.ylabel('child_mort',fontsize=13)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - Plot shows that whereever income is low child_mortality is high which indicates average income to the person is strong indicator in mortality rate\n",
    "   - Three clusters has been well explained in the data as shown above.\n",
    "   - Cluster 0 will be our priority where we observed high child_mortality rate and less average income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = 'income', y ='gdpp', hue = 'cluster', data =data2,palette=['blue','green','red'])\n",
    "plt.xlabel('income',fontsize=13)\n",
    "plt.ylabel('gdpp',fontsize=13)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - NetIncome per person looks linearly related with GDP of a country\n",
    "   - When the average income of the person increases GDP gradually increases\n",
    "   - We can consider countries with less average income and less gdpp wherethe trust can provide the funds and help them.      - As observed cluster 0 will be our criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = 'child_mort', y ='gdpp', hue = 'cluster', data =data2,palette=['blue','green','red'])\n",
    "plt.xlabel('child_mort',fontsize=13)\n",
    "plt.ylabel('gdpp',fontsize=13)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - As observed in the above plot `child_mort` is high when `gdpp` is low\n",
    "   - `gdpp` is a strong indicator for `child_mort`\n",
    "   - As observed cluster 0 tells about high child mortality rate\n",
    "   - In further steps we will filter the countries where this pattern is observed\n",
    "   - We can concentrate on cluster 0 where child_mort is high and gdpp is less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# scaling\n",
    "# Create new dataframe data3  with features: gdpp, child_mort and income and apply minmax scaler\n",
    "data2_columns=data2.iloc[:,:-2].columns\n",
    "data3=pd.DataFrame(mm.fit_transform(data2.iloc[:,:-2]),columns=data2_columns)\n",
    "data3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - After scaling the data we are storing them in data3 \n",
    "   - We have applied the min max scaler in the previous step its good that we scale the data since considering the data without scaling will give high priority to higher values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cluster value to data3\n",
    "data3['cluster']=data2['cluster']\n",
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add country column to data3\n",
    "data3['country']=data2['country']\n",
    "data3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - In the above two steps we have added country and cluster lables to the dataframe data3 which helps in further steps in identifying which country falls under which cluster group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group the clusters\n",
    "data3.groupby('cluster').mean().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - Now we know that cluster 0 is having high child_mort, low income and gdpp these are the fields we need to concentrate to help the people in this region and provide help which requires help from charity/Trust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considering cluster : 0 as priority in our scenario lets see which countries fall under cluster 0 which requires help when compared with countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3[data3['cluster']==0].sort_values(by=['child_mort','gdpp','income'],ascending=[False,True,True]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "   - Countries having High child_mortality rate, Low gdpp and low income is considred on priority where Trust can spend the money for needy people.\n",
    "   - As shown above countries are kept in order which required Trust help on priority\n",
    "   - The order of countries which require help is in the following order : `Haiti`,`Sierra Leone`,`Chad`, `Central African Republic` and ` Mali`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from scipy.cluster.hierarchy import cut_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe which we will use in hierarchical clustering\n",
    "data3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agglomerative clustering\n",
    "- Here we consider each data point as one cluster and we find the distance from each point to the other data points.Then the data points with minimum distance is formed as a cluster resulting in n-1 cluster\n",
    "- This process iterates until all the data points are formed as a single cluster\n",
    "- We can visualize the dendograms obtained which we will see in further steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### single linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))\n",
    "dendogram(linkage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single linkage\n",
    "plt.figure(figsize=(16,8))\n",
    "single_linkage=linkage(data3.iloc[:,:-2],method='single',metric='euclidean')   #single linkage method\n",
    "dendrogram(single_linkage)  #This prints the dendograms \n",
    "plt.show()          #display the dendogram on the screen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "- As seen in the above diagram the dendogram is tightly coupled lets try other linkage methods like complete and average linkage methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete linkage\n",
    "plt.figure(figsize=(16,8))\n",
    "complete_linkage=linkage(data3.iloc[:,:-2],method='complete',metric='euclidean')   #Complete linkage method\n",
    "dendrogram(complete_linkage)  #This prints the dendograms \n",
    "plt.show()          #display the dendogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "- We could see that complete linkage performe better than sngle linkage and clear dendograms has been formed, Lets cut the tree at different levels and find the optimal cluster value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average linkage\n",
    "plt.figure(figsize=(15,8))\n",
    "avg_linkage=linkage(data3.iloc[:,:-2],method='average',metric='euclidean')   #Average linkage method \n",
    "dendrogram(avg_linkage)  #this prints the dendograms \n",
    "plt.show()          #display the dendogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "- We have obtained Dendogrames for Single linkage, Complete linkage and average linkage tree.\n",
    "- Lets cut the tree to obtain the k value at 3 and 2.Then we can come to conclusion which is performng better   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `n_clusters=2` With complete Linkage method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels=cut_tree(complete_linkage,2).reshape(-1,)\n",
    "cluster_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- Now we got cluster labels when number of cluster is 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the cluster lables to the dataframe 'data3'\n",
    "data3['cluster_labels']=cluster_labels\n",
    "data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the count of cluster lables in data3\n",
    "data3.cluster_labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As observed we have 129 countries which fall unders cluster 0 and 38 countries which fall under cluster 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `n_clusters=3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels=cut_tree(complete_linkage,3).reshape(-1,)\n",
    "cluster_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- Now we got cluster labels when number of cluster is 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3['cluster_labels']=cluster_labels\n",
    "data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.cluster.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As observed we have 96 countries fall unders cluster 0, 31 countries fall under cluster1 and 40 countries fall under cluster 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe data4 which holds gdpp,child_mort,income,country and cluster_labels column\n",
    "data4=data3.drop('cluster',axis=1)#[['gdpp','child_mort','income','cluster_labels']]\n",
    "data4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets Group the data based on cluster labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the dataframe by cluster_labels\n",
    "data4.groupby('cluster_labels').mean().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "\n",
    "- Cluster 0 is having high `child_mort`,less`gdpp` and `income` which is a good indicator for the people required in aid.\n",
    "- Cluster 0 can be concentrated to provide help to the people in that countries which are in need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the cluster 0 labels includes country names\n",
    "data4[data4.cluster_labels==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 countries which requires\n",
    "data4[data4['cluster_labels']==0].sort_values(by=['child_mort','gdpp','income'],ascending=[False,True,True]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- HELP International can concentrate on this top 5 countries on priority in fighting the poverty and providing the people of backward countries with basic amenities and relief during the time of disasters and natural calamities. \n",
    "- As shown above countries are kept in order which required Trust help on priority\n",
    "- The order of countries which require help is in the following order : `Haiti`,`Sierra Leone`,`Chad`, `Central African Republic` and ` Mali`\n",
    "- We can cut the tree at different level to obtain different cluster value based on business understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Insights:\n",
    "- HELP International can concentrate on this Top 5 countries which are in need of help.The order of countries which require help is in the following order : `Haiti`,`Sierra Leone`,`Chad`, `Central African Republic` and ` Mali`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
