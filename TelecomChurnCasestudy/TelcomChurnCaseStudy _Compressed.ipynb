{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement:\n",
    "- In the telecom industry, customers are able to choose from multiple service providers and actively switch from one operator to another. In this highly competitive market, the telecommunications industry experiences an average of 15-25% annual churn rate. Given the fact that it costs 5-10 times more to acquire a new customer than to retain an existing one, customer retention has now become even more important than customer acquisition.<br><br>\n",
    "- For many incumbent operators, retaining high profitable customers is the number one business goal.<br><br>\n",
    "- To reduce customer churn, telecom companies need to predict which customers are at high risk of churn.<br><br>\n",
    "- In this project, we will analyse customer-level data of a leading telecom firm, build predictive models to identify customers at high risk of churn and identify the main indicators of churn.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WKQB4fxmiZdn"
   },
   "outputs": [],
   "source": [
    "# Import Required Librarues\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import statsmodels as sm\n",
    "import cufflinks\n",
    "cufflinks.go_offline()\n",
    "cufflinks.set_config_file(world_readable=True, theme='pearl')\n",
    "\n",
    "from IPython.display import Image  \n",
    "from six import StringIO  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus, graphviz\n",
    "pd.set_option('max_columns',500)\n",
    "pd.set_option('max_rows',200)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "uHIA6av9i8gU",
    "outputId": "29756c8c-bbf1-454a-e522-1cddb227938e"
   },
   "outputs": [],
   "source": [
    "# Import the data in data variable\n",
    "data=pd.read_csv('telecom_churn_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0E-Lonhqi8wm",
    "outputId": "f19ab3e8-7853-4ee4-cdd7-4b39bfebefae"
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "ORxiBbe4i8zR",
    "outputId": "fe513728-28a4-49b1-fe14-a781236eb71d"
   },
   "outputs": [],
   "source": [
    "#statstical description of the data\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O7pwqpuji852",
    "outputId": "a89d835f-dc19-4463-832b-9d4a2b42e170"
   },
   "outputs": [],
   "source": [
    "# Shape of the data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LesT0tkn75A"
   },
   "source": [
    "**Insights and Observations**\n",
    "- 1 lakh rows and 226 columns\n",
    "- Some columns just have 0 values eg: loc_og_t2o_mou which can be removed while cleaning the data\n",
    "- Some columns like total recharge data have lowest value as 1 - the null values could mean that the customer did not recharge and can be imputed with 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null value check and treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AdbqkELii88P",
    "outputId": "eaa43e43-7d50-488e-e249-4047c0910750"
   },
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "In the recharge variables where min value is 1, we can impute missing values with 0 since it shows customer didn't recharge in that month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of recharge columns where we will impute missing values with zeroes\n",
    "z_impute = ['total_rech_data_6', 'total_rech_data_7', 'total_rech_data_8', 'total_rech_data_9',\n",
    "        'av_rech_amt_data_6', 'av_rech_amt_data_7', 'av_rech_amt_data_8', 'av_rech_amt_data_9',\n",
    "        'max_rech_data_6', 'max_rech_data_7', 'max_rech_data_8', 'max_rech_data_9']\n",
    "\n",
    "# impute missing values with 0\n",
    "data[z_impute] = data[z_impute].apply(lambda x: x.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make sure values are imputed correctly\n",
    "print(\"Missing value ratio:\\n\")\n",
    "print(data[z_impute].isnull().sum()*100/data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-mn5oRQWoAPX",
    "outputId": "a474e565-2fa1-46cb-8d5f-8b0a4ca86baa"
   },
   "outputs": [],
   "source": [
    "# null values greater than 30percent\n",
    "nullperce=data.isnull().sum()/data.shape[0]\n",
    "nullgreaterthan30=nullperce[nullperce>0.3]\n",
    "nullgreaterthan30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_6cW9X4NoFan",
    "outputId": "42f5cb0f-cbfb-47a0-f7df-dd3fa342e4be",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(nullgreaterthan30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- We could see that we have 40 features where null value count is greater than30 percent.\n",
    "- We are dropping these features now and we will consider only remaining features since these values may lead to bias and null value percentage less than 30 are treated in further steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XecAgtyeoJTn",
    "outputId": "ec785cbd-4632-40a9-d00a-362e8639f5a5"
   },
   "outputs": [],
   "source": [
    "#null vlaues less than 30 are considereed for further analysis\n",
    "nulllessthan30=nullperce[nullperce<=0.3]\n",
    "nulllessthan30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "id": "tZJ2m5mFoJs0",
    "outputId": "f174f4b4-8915-4b1b-e78c-9053730082b1"
   },
   "outputs": [],
   "source": [
    "data2=data[nulllessthan30.index]\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- In the above two columns we have performed null value check percentage and created a new dataframe `data2` which holds our new dataframe,In which null value peercentage of features is less than 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the number of columns having 2 & less than 2 unique values\n",
    "remcol = []\n",
    "for col in list(data2.columns):\n",
    "    uniqueValues = data2[col].unique()\n",
    "    if len(uniqueValues) < 3:\n",
    "        remcol.append(col)\n",
    "remcol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As shown above we are removing the above specified columns/features ,since each feature is saying same information to the dataset which will not help us,So we are removing from further analysis.\n",
    "- As an exmaple`circle_id` in this dataset is same for entire data.so considering these type of data may affet the peerfomance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing columns having very less variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mobile number is not a useful feature and thus it makes sense to remove it along with zero variance columns\n",
    "\n",
    "remcol.append('mobile_number')\n",
    "print(remcol)\n",
    "print(\"Before removing the columns shape of df {}\".format(data2.shape))\n",
    "\n",
    "for col in remcol:\n",
    "    data2=data2.drop(col,axis=1)\n",
    "\n",
    "print(\"After removing the columns shape of df {}\".format(data2.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Woau6ny2oiq1",
    "outputId": "5cf65623-7874-4e16-dbdb-8a41125406b6"
   },
   "outputs": [],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treating the null values\n",
    "- Lets validate the existing columns to fix the null values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns having less than 30% null values\n",
    "null_values = data2.isnull().sum()\n",
    "list_null_col = list(null_values[data2.isnull().sum()>0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we are not doing time series forecasting all the date columns can be removed\n",
    "\n",
    "df_date = data2.select_dtypes(exclude=['float64','int64'])\n",
    "\n",
    "print(\"Before removing the date columns shape of df {}\".format(data2.shape))\n",
    "\n",
    "for col in df_date.columns:\n",
    "    data2=data2.drop(col,axis=1)\n",
    "\n",
    "print(\"After removing the date columns shape of df {}\".format(data2.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the na values with mean vlaues\n",
    "data2.fillna(data2.mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the rest of null values with mean as all of them are numerical variables\n",
    "data2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "x5nQLfjSvh1j",
    "outputId": "3fd78ccb-0489-4c0e-ce71-f779b7bfc222"
   },
   "outputs": [],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xxMwXfnBvsBC",
    "outputId": "f09d6899-a6c7-41bb-f66a-2ee1dfabb92b"
   },
   "outputs": [],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering High value customers\n",
    "- Those who have recharged with an amount more than or equal to X, where X is the 70th percentile of the average recharge amount in the first two months (the good phase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I9fTNjkONYrW"
   },
   "outputs": [],
   "source": [
    "#Take average recharge amount in the month of 6 and 7 adn store in a new clumn called avergae_rech_amt_6_7\n",
    "\n",
    "data2['average_rech_amt_6_7']=(data2['total_rech_amt_6']+data2['total_rech_amt_7'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6IWXXTwlPnIs",
    "outputId": "bb7cab12-bf3e-4e28-e76c-f4abef4d52f0"
   },
   "outputs": [],
   "source": [
    "#check the quantile values since we will consider the value abve 70 percentile as high value customers\n",
    "np.quantile(data2['average_rech_amt_6_7'],[0,0.5,0.7,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZjkJ_OV8QCCE",
    "outputId": "53c4fa23-e2a2-459a-c5a1-585229c934d9"
   },
   "source": [
    "**Insights**:\n",
    "- As we could see value of ~390 is the 70th percentile value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "G_3dqK_pQV87",
    "outputId": "5841fa36-061d-4708-e39b-148aeff52fcc"
   },
   "outputs": [],
   "source": [
    "data3=data2[data2['average_rech_amt_6_7']>=368.5]\n",
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5S_MZp2YQ5hd",
    "outputId": "7e664293-9691-41dc-b39e-7c033064db79"
   },
   "outputs": [],
   "source": [
    "data3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- Now we are having 30011 rows of data, Which was formed after considering only high vlaue customers.\n",
    "- Lets continue our analysis with this data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVJYW_k7UNd8"
   },
   "source": [
    "## Identify churners where any of the following fields are 0\n",
    "- `total_ic_mou_9`\n",
    "- `total_og_mou_9`\n",
    "- `vol_2g_mb_9`\n",
    "- `vol_3g_mb_9`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0eAY3jutRSyT",
    "outputId": "860a5aba-599b-46f0-d83d-94cf78e4add1"
   },
   "outputs": [],
   "source": [
    "data3['total_ic_mou_9'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4FwJcQk3TPgj",
    "outputId": "99083f5c-9451-4e23-f4ea-1553ad916f3b"
   },
   "outputs": [],
   "source": [
    "data3['total_og_mou_9'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2fLyzdRzTccU",
    "outputId": "5e652d2e-9249-4fe0-f832-762d92ea2f78"
   },
   "outputs": [],
   "source": [
    "data3['vol_2g_mb_9'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SpDJgNo2ToAb",
    "outputId": "bbea8e11-8a6c-4218-c12c-a9f6c8297f3a"
   },
   "outputs": [],
   "source": [
    "data3['vol_3g_mb_9'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DjbjGxz-T6oa"
   },
   "source": [
    "### Now when all of the above fields are 0 then we can tag them as churners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "utgNzId1q2sL",
    "outputId": "c5dea376-4b23-4d10-de20-f6ac757d702b"
   },
   "outputs": [],
   "source": [
    "data3['churn']=((data3['total_ic_mou_9']==0.00) & (data3['total_og_mou_9']==0.00 ) & (data3['vol_2g_mb_9']==0.00) & (data3['vol_3g_mb_9']==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "Yu8-E3ndraAz",
    "outputId": "28f8e35d-8dfb-44c9-c42e-2c2c4ac301ff"
   },
   "outputs": [],
   "source": [
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MbOs3OTYsKT0"
   },
   "outputs": [],
   "source": [
    "# Funcc is reusable method for converting the values of True and False to numericla format indicating churn and nonchurn\n",
    "def funcc(inp):\n",
    "    if(inp==False):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pXyJc7PurJe3",
    "outputId": "0becc581-8e5c-48c2-bd59-db0b48e86707"
   },
   "outputs": [],
   "source": [
    "data3['churn']=data3['churn'].apply(funcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EDHtNwTXZsdb",
    "outputId": "6d38a027-8c7e-432f-d26a-dbd4e4df625e"
   },
   "outputs": [],
   "source": [
    "temp = data3['churn'].value_counts()\n",
    "df_1 = pd.DataFrame({'labels': temp.index,'values': temp.values})\n",
    "df_1.iplot(kind='pie',labels='labels',values='values', title=\"% Data Imbalance\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights and Observations**\n",
    "   - The churn rate of ~8.6% is very small and it would bias the model to the majority class. Thus we need to use class balance techniques like SMOTE on training data before running the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing the columns having '_9' and sept post preparing churn column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZUrMoojIZnlm"
   },
   "outputs": [],
   "source": [
    "listofcolumns2=[]\n",
    "eliminatecolumns=[]\n",
    "for i in data3.columns:\n",
    "    if('_9' in i):\n",
    "        eliminatecolumns.append(i)\n",
    "    else:\n",
    "        listofcolumns2.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gyy1u9BuBFrL",
    "outputId": "a92705b2-c996-424e-f381-523af6001871"
   },
   "outputs": [],
   "source": [
    "print(len(listofcolumns2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MSjnVOX7BMy3",
    "outputId": "3a18775b-90f9-44fe-cb32-190ab89ff046"
   },
   "outputs": [],
   "source": [
    "print(len(eliminatecolumns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- As shown above we are removing the columns where we have 9th data in it and we could observe 43 columns can be removed after applying this condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Amdy9HT5DYD1",
    "outputId": "13b9bea9-517d-4e43-f58a-4b7e34bedad2"
   },
   "outputs": [],
   "source": [
    "# As showed above we have removed columns perfectly which are not required for further analysis\n",
    "data4=data3[listofcolumns2]\n",
    "data4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing variable calculated in Sept \n",
    "data4.drop('sep_vbc_3g',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- Removing variable calculated in Sept  which is the last month of the data which we are using to make predicions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iq9RKs8JDzRv"
   },
   "source": [
    "# Step 3 Visualizing and Deriving variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns left in dataset post cleaning\n",
    "list(data4.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the variables through box plot\n",
    "def pltbox(r,c,columns):\n",
    "    for i,col in zip(range(1,(r*c)+1),columns):\n",
    "        plt.subplot(r,c,i)\n",
    "        sns.boxplot(y = col,x='churn', data = data4, hue='churn',palette=(\"Set3\"),showfliers=False)\n",
    "        plt.tight_layout(pad=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing the mean across different variable across three months\n",
    "def plot_mean_bar_chart(df,columns_list):\n",
    "    df_0 = df[df.churn==0].filter(columns_list)\n",
    "    df_1 = df[df.churn==1].filter(columns_list)\n",
    "\n",
    "    mean_df_0 = pd.DataFrame([df_0.mean()],index={'Non Churn'})\n",
    "    mean_df_1 = pd.DataFrame([df_1.mean()],index={'Churn'})\n",
    "\n",
    "    frames = [mean_df_0, mean_df_1]\n",
    "    mean_bar = pd.concat(frames)\n",
    "\n",
    "    mean_bar.T.plot.line(figsize=(10,5),rot=0)\n",
    "    plt.show()\n",
    "    \n",
    "    return mean_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total recharge number and amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "pltbox(2,3,['total_rech_num_6','total_rech_num_7','total_rech_num_8','total_rech_amt_6','total_rech_amt_7','total_rech_amt_8'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['total_rech_num_6','total_rech_num_7','total_rech_num_8'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['total_rech_amt_6','total_rech_amt_7','total_rech_amt_8'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "\n",
    "The total amount recharge and number drops from June to August for churn users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average revenue per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "pltbox(1,3,['arpu_6','arpu_7','arpu_8'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['arpu_6','arpu_7','arpu_8'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "\n",
    "- There are negative values in these three variables which can be brought to same scale through Standard scaler\n",
    "- Initially average revenue per user for churn cases is much higher than non churn users but it drops with month and becomes very low in August"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Onnet v.s Offnet calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "pltbox(2,3,['onnet_mou_6','onnet_mou_7','onnet_mou_8','offnet_mou_6','offnet_mou_7','offnet_mou_8'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['onnet_mou_6','onnet_mou_7','onnet_mou_8'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['offnet_mou_6','offnet_mou_7','offnet_mou_8'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "\n",
    "The minutes of usage decreses with a higher slope during August for both within network and outside network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roaming Incoming v.s Outgoing calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "pltbox(2,3,['roam_ic_mou_6','roam_ic_mou_7','roam_ic_mou_8','roam_og_mou_6','roam_og_mou_7','roam_og_mou_8'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['roam_ic_mou_6','roam_ic_mou_7','roam_ic_mou_8'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['roam_og_mou_6','roam_og_mou_7','roam_og_mou_8'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "\n",
    "The roaming minutes of usage for churned users is much higher compared to non churners. The mean pretty much remains constant throughout the three month time period. This could mean that lot of churners have moved out of state or travel most of the times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outgoing calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outgoing calls within network v.s outside network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "pltbox(2,3,['loc_og_t2t_mou_6',\n",
    " 'loc_og_t2t_mou_7',\n",
    " 'loc_og_t2t_mou_8',\n",
    " 'loc_og_t2m_mou_6',\n",
    " 'loc_og_t2m_mou_7',\n",
    " 'loc_og_t2m_mou_8'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['loc_og_t2t_mou_6',\n",
    " 'loc_og_t2t_mou_7',\n",
    " 'loc_og_t2t_mou_8'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['loc_og_t2m_mou_6',\n",
    " 'loc_og_t2m_mou_7',\n",
    " 'loc_og_t2m_mou_8'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "\n",
    "Out going calls within network and out side network reduces drastically by August for churned users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outgoing calls to fixed lines of T v.s it's own call center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "pltbox(2,3,['loc_og_t2f_mou_6',\n",
    " 'loc_og_t2f_mou_7',\n",
    " 'loc_og_t2f_mou_8',\n",
    " 'loc_og_t2c_mou_6',\n",
    " 'loc_og_t2c_mou_7',\n",
    " 'loc_og_t2c_mou_8'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['loc_og_t2f_mou_6',\n",
    " 'loc_og_t2f_mou_7',\n",
    " 'loc_og_t2f_mou_8'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['loc_og_t2c_mou_6',\n",
    " 'loc_og_t2c_mou_7',\n",
    " 'loc_og_t2c_mou_8'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "\n",
    "Out going calls to network call centre increased drastically in July and then reduced in August for churned users. It could be because the customers weren't happy with the services provided and had decided to leave the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outgoing local calls - within same telecome circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "pltbox(2,3,['loc_og_mou_6',\n",
    " 'loc_og_mou_7',\n",
    " 'loc_og_mou_8'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['loc_og_mou_6',\n",
    " 'loc_og_mou_7',\n",
    " 'loc_og_mou_8'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "\n",
    "Out going calls within network and out side network reduces drastically by August for churned users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outgoing STD calls - within same telecome circle (within n/w outside n/w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "pltbox(2,3,['std_og_t2t_mou_6',\n",
    " 'std_og_t2t_mou_7',\n",
    " 'std_og_t2t_mou_8',\n",
    " 'std_og_t2m_mou_6',\n",
    " 'std_og_t2m_mou_7',\n",
    " 'std_og_t2m_mou_8'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['std_og_t2t_mou_6',\n",
    " 'std_og_t2t_mou_7',\n",
    " 'std_og_t2t_mou_8'\n",
    " ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['std_og_t2m_mou_6',\n",
    " 'std_og_t2m_mou_7',\n",
    " 'std_og_t2m_mou_8'\n",
    " ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "\n",
    "STD Out going calls within network and out side network reduces drastically by August for churned users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outgoing STD calls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "pltbox(2,3,['std_og_t2f_mou_6',\n",
    " 'std_og_t2f_mou_7',\n",
    " 'std_og_t2f_mou_8',\n",
    " 'std_og_mou_6',\n",
    " 'std_og_mou_7',\n",
    " 'std_og_mou_8',\n",
    " ])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['std_og_t2f_mou_6',\n",
    " 'std_og_t2f_mou_7',\n",
    " 'std_og_t2f_mou_8'\n",
    " ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['std_og_mou_6',\n",
    " 'std_og_mou_7',\n",
    " 'std_og_mou_8',\n",
    " ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "\n",
    "STD Out going calls reduces drastically from July to August for churned users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Others and total outgoing mou calls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "pltbox(2,3,['isd_og_mou_6',\n",
    " 'isd_og_mou_7',\n",
    " 'isd_og_mou_8',\n",
    " 'spl_og_mou_6',\n",
    " 'spl_og_mou_7',\n",
    " 'spl_og_mou_8'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['isd_og_mou_6',\n",
    " 'isd_og_mou_7',\n",
    " 'isd_og_mou_8',\n",
    " ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,[ 'spl_og_mou_6',\n",
    " 'spl_og_mou_7',\n",
    " 'spl_og_mou_8'\n",
    " ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "\n",
    "ISD and special out going calls reduces drastically from July to August for churned users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ISD v.s Special calls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "pltbox(2,3,['og_others_6',\n",
    " 'og_others_7',\n",
    " 'og_others_8',\n",
    " 'total_og_mou_6',\n",
    " 'total_og_mou_7',\n",
    " 'total_og_mou_8'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['og_others_6',\n",
    " 'og_others_7',\n",
    " 'og_others_8'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['total_og_mou_6',\n",
    " 'total_og_mou_7',\n",
    " 'total_og_mou_8'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "\n",
    "Total out going calls reduces drastically from July to August for churned users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incoming calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### incoming calls within network v.s outside network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "pltbox(2,3,['loc_ic_t2t_mou_6',\n",
    " 'loc_ic_t2t_mou_7',\n",
    " 'loc_ic_t2t_mou_8',\n",
    " 'loc_ic_t2m_mou_6',\n",
    " 'loc_ic_t2m_mou_7',\n",
    " 'loc_ic_t2m_mou_8'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['loc_ic_t2t_mou_6',\n",
    " 'loc_ic_t2t_mou_7',\n",
    " 'loc_ic_t2t_mou_8'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['loc_ic_t2m_mou_6',\n",
    " 'loc_ic_t2m_mou_7',\n",
    " 'loc_ic_t2m_mou_8'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "\n",
    "incoming calls within network and inside network reduces drastically by August for churned users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### incoming calls to fixed lines of T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "pltbox(2,3,['loc_ic_t2f_mou_6',\n",
    " 'loc_ic_t2f_mou_7',\n",
    " 'loc_ic_t2f_mou_8'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['loc_ic_t2f_mou_6',\n",
    " 'loc_ic_t2f_mou_7',\n",
    " 'loc_ic_t2f_mou_8'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### incoming local calls - within same telecome circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "pltbox(2,3,['loc_ic_mou_6',\n",
    " 'loc_ic_mou_7',\n",
    " 'loc_ic_mou_8'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['loc_ic_mou_6',\n",
    " 'loc_ic_mou_7',\n",
    " 'loc_ic_mou_8'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "\n",
    "incoming calls within network and inside network reduces drastically by August for churned users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### incoming STD calls - within same telecome circle (within n/w outside n/w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "pltbox(2,3,['std_ic_t2t_mou_6',\n",
    " 'std_ic_t2t_mou_7',\n",
    " 'std_ic_t2t_mou_8',\n",
    " 'std_ic_t2m_mou_6',\n",
    " 'std_ic_t2m_mou_7',\n",
    " 'std_ic_t2m_mou_8'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['std_ic_t2t_mou_6',\n",
    " 'std_ic_t2t_mou_7',\n",
    " 'std_ic_t2t_mou_8'\n",
    " ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['std_ic_t2m_mou_6',\n",
    " 'std_ic_t2m_mou_7',\n",
    " 'std_ic_t2m_mou_8'\n",
    " ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "\n",
    "STD incoming calls within network and inside network reduces drastically by August for churned users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### incoming STD calls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "pltbox(2,3,['std_ic_t2f_mou_6',\n",
    " 'std_ic_t2f_mou_7',\n",
    " 'std_ic_t2f_mou_8',\n",
    " 'std_ic_mou_6',\n",
    " 'std_ic_mou_7',\n",
    " 'std_ic_mou_8',\n",
    " ])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['std_ic_t2f_mou_6',\n",
    " 'std_ic_t2f_mou_7',\n",
    " 'std_ic_t2f_mou_8'\n",
    " ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['std_ic_mou_6',\n",
    " 'std_ic_mou_7',\n",
    " 'std_ic_mou_8',\n",
    " ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "\n",
    "STD incoming calls reduces drastically from July to August for churned users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Others and total incoming mou calls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "pltbox(2,3,['isd_ic_mou_6',\n",
    " 'isd_ic_mou_7',\n",
    " 'isd_ic_mou_8',\n",
    " 'spl_ic_mou_6',\n",
    " 'spl_ic_mou_7',\n",
    " 'spl_ic_mou_8'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['isd_ic_mou_6',\n",
    " 'isd_ic_mou_7',\n",
    " 'isd_ic_mou_8',\n",
    " ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,[ 'spl_ic_mou_6',\n",
    " 'spl_ic_mou_7',\n",
    " 'spl_ic_mou_8'\n",
    " ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "\n",
    "ISD and special incoming calls reduces drastically from July to August for churned users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ISD v.s Special calls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "pltbox(2,3,['ic_others_6',\n",
    " 'ic_others_7',\n",
    " 'ic_others_8',\n",
    " 'total_ic_mou_6',\n",
    " 'total_ic_mou_7',\n",
    " 'total_ic_mou_8'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['ic_others_6',\n",
    " 'ic_others_7',\n",
    " 'ic_others_8'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['total_ic_mou_6',\n",
    " 'total_ic_mou_7',\n",
    " 'total_ic_mou_8'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "\n",
    "Total incoming calls reduces drastically from July to August for churned users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max recharge v.s last day recharge amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "pltbox(2,3,['max_rech_amt_6',\n",
    " 'max_rech_amt_7',\n",
    " 'max_rech_amt_8','last_day_rch_amt_6',\n",
    " 'last_day_rch_amt_7',\n",
    " 'last_day_rch_amt_8'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['max_rech_amt_6',\n",
    " 'max_rech_amt_7',\n",
    " 'max_rech_amt_8'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['last_day_rch_amt_6',\n",
    " 'last_day_rch_amt_7',\n",
    " 'last_day_rch_amt_8'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "\n",
    "The max and last recharge amount reduces from July to August"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2G / 3G packs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volume based 2g v.s 3g plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "pltbox(2,3,['vol_2g_mb_6',\n",
    " 'vol_2g_mb_7',\n",
    " 'vol_2g_mb_8',\n",
    " 'vol_3g_mb_6',\n",
    " 'vol_3g_mb_7',\n",
    " 'vol_3g_mb_8'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['vol_2g_mb_6',\n",
    " 'vol_2g_mb_7',\n",
    " 'vol_2g_mb_8'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['vol_3g_mb_6',\n",
    " 'vol_3g_mb_7',\n",
    " 'vol_3g_mb_8'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "\n",
    "The volume of 2g/3g mobile data usage reduces for churned customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### monthly v.s sachet 2G plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The values present in monthly/sachet plans seems to be categories(months/days) opted by different user\n",
    "data4.monthly_2g_6.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the data type for the categorical variables\n",
    "\n",
    "#data4 = data4.astype({\"monthly_2g_6\":'object',\"monthly_2g_7\":'object',\"monthly_2g_8\":'object',\"sachet_2g_6\":'object',\"sachet_2g_7\":'object',\"sachet_2g_8\":'object'})\n",
    "#data4[['monthly_2g_6',\n",
    "# 'monthly_2g_7',\n",
    " #'monthly_2g_8']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot multiple bar charts\n",
    "def pltvar(r,c,columns,rot=45):\n",
    "    for i,col in zip(range(1,(r*c)+1),columns):\n",
    "        plt.subplot(r,c,i)\n",
    "        plt.title('Distribution of Catgeories in '+col+ ' Feature',size=10,color='Green')\n",
    "        sns.countplot(x=col,hue='churn',data=data4)\n",
    "        plt.xticks(rotation=rot)\n",
    "        plt.tight_layout(pad=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "pltvar(2,2,['monthly_2g_6',\n",
    " 'monthly_2g_7',\n",
    " 'monthly_2g_8'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "pltvar(2,2,['sachet_2g_6',\n",
    " 'sachet_2g_7',\n",
    " 'sachet_2g_8'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "\n",
    "The monthly/sachet plans usage is least churned customers across all three months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### monthly v.s sachet 3g plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4.monthly_3g_6.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the data type for the categorical variables\n",
    "\n",
    "#data4 = data4.astype({\"monthly_3g_6\":'object',\"monthly_3g_7\":'object',\"monthly_3g_8\":'object',\"sachet_3g_6\":'object',\"sachet_3g_7\":'object',\"sachet_3g_8\":'object'})\n",
    "#data4[['monthly_3g_6',\n",
    "# 'monthly_3g_7',\n",
    "# 'monthly_3g_8']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "pltvar(2,2,['monthly_3g_6',\n",
    " 'monthly_3g_7',\n",
    " 'monthly_3g_8'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "pltvar(2,2,['sachet_3g_6',\n",
    " 'sachet_3g_7',\n",
    " 'sachet_3g_8'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "\n",
    "The monthly/sachet plans usage reduces reduces for churned customers from July to August"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age on network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "pltbox(2,3,['aon'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "\n",
    "The churned users have stayed a very short time on the network compared to non churners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['monthly_3g_6',\n",
    " 'monthly_3g_7',\n",
    " 'monthly_3g_8'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['sachet_3g_6',\n",
    " 'sachet_3g_7',\n",
    " 'sachet_3g_8'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "\n",
    "The monthly/sachet plans usage reduces reduces for churned customers from July to August"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volume based cost 3g plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "pltbox(2,3,['aug_vbc_3g','jul_vbc_3g','jun_vbc_3g'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean across the months\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_mean_bar_chart(data4,['aug_vbc_3g','jul_vbc_3g','jun_vbc_3g'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "\n",
    "Volume based plan enrollment reduces from June to August for churned users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Treatment\n",
    "- A lot of variables have outliers which can be observed in the visualization in box plots.\n",
    "- They can be capped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integer columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_columns=data4.select_dtypes(include='int64').columns\n",
    "int_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_columns=list(int_columns[:-1])\n",
    "int_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in int_columns:\n",
    "    print(\"quantile values :\",i)\n",
    "    quantile_values=(np.quantile(data4[i],[0.0,0.05,0.1,0.2,0.9,0.95,0.99,1.0]))\n",
    "    for i,j in zip([0.0,0.05,0.1,0.2,0.9,0.95,0.99,1.0],quantile_values):\n",
    "        print(i,'----', j )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights and observations:\n",
    "\n",
    "- We could see from the above cell that there are outiers present in majority of the columns where we could see big difference in the vlaues from 99th perntile values to 100 th percentile values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Capping outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len_intcolumns=len(int_columns)\n",
    "\n",
    "for i,j in zip(int_columns,range(len_intcolumns)):\n",
    "    percentilevalues = data4[i].quantile([0.0,0.99]).values\n",
    "    data4[i] = np.clip(data4[i], percentilevalues[0], percentilevalues[1])  # Replace the original features after capping the data in the original dataframe \n",
    "data4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in int_columns:\n",
    "    print(\"quantile values After capping :\",i)\n",
    "    quantile_values=(np.quantile(data4[i],[0.0,0.05,0.1,0.2,0.9,0.95,0.99,1.0]))\n",
    "    for i,j in zip([0.0,0.05,0.1,0.2,0.9,0.95,0.99,1.0],quantile_values):\n",
    "        print(i,'----', j )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights;\n",
    "- As we can see from  the above cell we have capped the values correctly which is good for further analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Float variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Float\n",
    "\n",
    "float_columns=data4.select_dtypes(include='float64').columns\n",
    "float_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in float_columns:\n",
    "    print(\"quantile values :\",i)\n",
    "    quantile_values=(np.quantile(data4[i],[0.0,0.05,0.1,0.2,0.9,0.95,0.99,1.0]))\n",
    "    for i,j in zip([0.0,0.05,0.1,0.2,0.9,0.95,0.99,1.0],quantile_values):\n",
    "        print(i,'----', j )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len_floatcolumns=len(float_columns)\n",
    "\n",
    "for i,j in zip(float_columns,range(len_floatcolumns)):\n",
    "    percentilevalues = data4[i].quantile([0.0,0.99]).values\n",
    "    data4[i] = np.clip(data4[i], percentilevalues[0], percentilevalues[1])  # Replace the original features after capping the data in the original dataframe \n",
    "data4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in float_columns:\n",
    "    print(\"quantile values After capping :\",i)\n",
    "    quantile_values=(np.quantile(data4[i],[0.0,0.05,0.1,0.2,0.9,0.95,0.99,1.0]))\n",
    "    for i,j in zip([0.0,0.05,0.1,0.2,0.9,0.95,0.99,1.0],quantile_values):\n",
    "        print(i,'----', j )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights;\n",
    "- As we can see from  the above cell we have capped the values correctly which is good for further analysis\n",
    "- So we have treated all the columns with integer and float datatype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derived Variables\n",
    "- Difference between the recharge/calls/mou at month 8 with average of month 6 & 7\n",
    "- This variable could bring important information about how much was the difference for the customers who are loyal and once who plan to churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4['arpu_diff'] = data4.arpu_8 - ((data4.arpu_6 + data4.arpu_7)/2)\n",
    "\n",
    "data4['onnet_mou_diff'] = data4.onnet_mou_8 - ((data4.onnet_mou_6 + data4.onnet_mou_7)/2)\n",
    "\n",
    "data4['offnet_mou_diff'] = data4.offnet_mou_8 - ((data4.offnet_mou_6 + data4.offnet_mou_7)/2)\n",
    "\n",
    "data4['roam_ic_mou_diff'] = data4.roam_ic_mou_8 - ((data4.roam_ic_mou_6 + data4.roam_ic_mou_7)/2)\n",
    "\n",
    "data4['roam_og_mou_diff'] = data4.roam_og_mou_8 - ((data4.roam_og_mou_6 + data4.roam_og_mou_7)/2)\n",
    "\n",
    "data4['loc_og_mou_diff'] = data4.loc_og_mou_8 - ((data4.loc_og_mou_6 + data4.loc_og_mou_7)/2)\n",
    "\n",
    "data4['std_og_mou_diff'] = data4.std_og_mou_8 - ((data4.std_og_mou_6 + data4.std_og_mou_7)/2)\n",
    "\n",
    "data4['isd_og_mou_diff'] = data4.isd_og_mou_8 - ((data4.isd_og_mou_6 + data4.isd_og_mou_7)/2)\n",
    "\n",
    "data4['spl_og_mou_diff'] = data4.spl_og_mou_8 - ((data4.spl_og_mou_6 + data4.spl_og_mou_7)/2)\n",
    "\n",
    "data4['total_og_mou_diff'] = data4.total_og_mou_8 - ((data4.total_og_mou_6 + data4.total_og_mou_7)/2)\n",
    "\n",
    "data4['loc_ic_mou_diff'] = data4.loc_ic_mou_8 - ((data4.loc_ic_mou_6 + data4.loc_ic_mou_7)/2)\n",
    "\n",
    "data4['std_ic_mou_diff'] = data4.std_ic_mou_8 - ((data4.std_ic_mou_6 + data4.std_ic_mou_7)/2)\n",
    "\n",
    "data4['isd_ic_mou_diff'] = data4.isd_ic_mou_8 - ((data4.isd_ic_mou_6 + data4.isd_ic_mou_7)/2)\n",
    "\n",
    "data4['spl_ic_mou_diff'] = data4.spl_ic_mou_8 - ((data4.spl_ic_mou_6 + data4.spl_ic_mou_7)/2)\n",
    "\n",
    "data4['total_ic_mou_diff'] = data4.total_ic_mou_8 - ((data4.total_ic_mou_6 + data4.total_ic_mou_7)/2)\n",
    "\n",
    "data4['total_rech_num_diff'] = data4.total_rech_num_8 - ((data4.total_rech_num_6 + data4.total_rech_num_7)/2)\n",
    "\n",
    "data4['total_rech_amt_diff'] = data4.total_rech_amt_8 - ((data4.total_rech_amt_6 + data4.total_rech_amt_7)/2)\n",
    "\n",
    "data4['max_rech_amt_diff'] = data4.max_rech_amt_8 - ((data4.max_rech_amt_6 + data4.max_rech_amt_7)/2)\n",
    "\n",
    "data4['vol_2g_mb_diff'] = data4.vol_2g_mb_8 - ((data4.vol_2g_mb_6 + data4.vol_2g_mb_7)/2)\n",
    "\n",
    "data4['vol_3g_mb_diff'] = data4.vol_3g_mb_8 - ((data4.vol_3g_mb_6 + data4.vol_3g_mb_7)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspecting one of the derived variables\n",
    "\n",
    "data4[['arpu_diff','arpu_6','arpu_7','arpu_8']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the variables which have been used to create new variables \n",
    "rem_col_1 = []\n",
    "col = ['arpu','onnet_mou','offnet_mou','roam_ic_mou','roam_og_mou','loc_og_mou','std_og_mou','isd_og_mou','spl_og_mou'\n",
    "       ,'total_og_mou','loc_ic_mou','std_ic_mou','isd_ic_mou','spl_ic_mou','total_ic_mou','total_rech_num'\n",
    "       ,'total_rech_amt','max_rech_amt','vol_2g_mb','vol_3g_mb']\n",
    "for i in col:\n",
    "    rem_col_1.append(i+'_6')\n",
    "    rem_col_1.append(i+'_7')\n",
    "    rem_col_1.append(i+'_8')\n",
    "\n",
    "data5 = data4.drop(rem_col_1,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining numerical variables\n",
    "df_numerical = data5.select_dtypes(exclude=['object'])\n",
    "df_numerical.shape\n",
    "df_refined = df_numerical.copy()\n",
    "df_refined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test-train split and Feature scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting feature variable to X\n",
    "X = df_refined.drop(['churn'], axis=1)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Putting response variable to y\n",
    "y = df_refined['churn']\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test (75%/25%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling in Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numerical_rem_churn = df_numerical.drop('churn',axis=1)\n",
    "df_numerical_rem_churn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the numerical variables\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train[list(df_numerical_rem_churn.columns)] = scaler.fit_transform(X_train[list(df_numerical_rem_churn.columns)])\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE technique to increase samples of churned customers compared to not churned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from imblearn.combine import SMOTETomek"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "smt=SMOTETomek(0.5,random_state=42)\n",
    "X_train_SMOTE, y_train_SMOTE = smt.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smt = SMOTE(0.5,random_state=42)\n",
    "X_train_SMOTE, y_train_SMOTE = smt.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the churn rate before and after applying SMOTE\n",
    "churn_1 = (sum(y_train)/len(y_train))*100\n",
    "churn_2 = (sum(y_train_SMOTE)/len(y_train_SMOTE))*100\n",
    "print(\"Before smote the number of records {} and the churn rate is {}\".format(len(y_train),round(churn_1,2)))\n",
    "print(\"After smote the number of records {} and the churn rate is {}\".format(len(y_train_SMOTE),round(churn_2,2)))\n",
    "print('Number of records in X_train before SMOTE {}'.format(len(X_train)))\n",
    "print('Number of records in X_train after SMOTE {}'.format(len(X_train_SMOTE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_SMOTE.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights and Observations**\n",
    "\n",
    "The up sampling has been done such that the number of churn cases increases from 8% to 50% and now the model can be build using the new training sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 Model Building and PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "- We have lot of features in the training set which can be reduced using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise PCA without any component size initially\n",
    "pca=PCA(random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(X_train_SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_cumu = np.cumsum(pca.explained_variance_ratio_)\n",
    "var_cumu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[12,8])\n",
    "#plt.vlines(x=60, ymax=1, ymin=0, colors=\"r\", linestyles=\"--\")\n",
    "plt.hlines(y=0.95, xmin=0,xmax=120, colors=\"g\", linestyles=\"--\")\n",
    "plt.plot(var_cumu)\n",
    "plt.ylabel(\"Cumulative variance explained\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_final = IncrementalPCA(n_components=65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_SMOTE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pca = pca_final.fit_transform(X_train_SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying PCA on test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_pca = pca_final.transform(X_test)\n",
    "df_test_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running first model - Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying logistic regression on the data on our Principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_pca = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pca = learner_pca.fit(df_train_pca, y_train_SMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- AUC value is 91 percent\n",
    "- AUC (Area under the curve) is more in this case which indicates good model since high AUC indicates high TPR and low FPR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs_train =model_pca.predict_proba(df_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the roc_auc_score\n",
    "\"ROC AUC Score for training set is {:2.2}\".format(metrics.roc_auc_score(y_train_SMOTE, pred_probs_train[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- AUC value is 85 percent on test data\n",
    "- AUC (Area under the curve) in this case indicates good model since high AUC indicates high TPR and low FPR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs_test = model_pca.predict_proba(df_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"ROC AUC Score for test set is {:2.2}\".format(metrics.roc_auc_score(y_test, pred_probs_test[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights and Obervations**\n",
    "\n",
    "The model seems to give fine output with 20 variables and doesn't seem to overfit on training set. However, lets check how the results are when we use PCA to explain 95 variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply pca which can explain 95 percent variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_again = PCA(0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA on X_train\n",
    "df_train_pca2 = pca_again.fit_transform(X_train_SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pca2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following it up with a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_pca2 = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression on training set\n",
    "model_pca2 = learner_pca2.fit(df_train_pca2, y_train_SMOTE)\n",
    "model_pca2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the x test based on PCA\n",
    "df_test_pca2 = pca_again.transform(X_test)\n",
    "df_test_pca2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_pca2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the model to predict target variable - df_train_pca2\n",
    "pred_probs_train2 =model_pca2.predict_proba(df_train_pca2)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the roc_auc_score\n",
    "\"ROC AUC Score for training set is {:2.2}\".format(metrics.roc_auc_score(y_train_SMOTE, pred_probs_train2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the model to predict target variable - df_test_pca2\n",
    "pred_probs_test2 = model_pca2.predict_proba(df_test_pca2)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"ROC AUC Score for test set is {:2.2}\".format(metrics.roc_auc_score(y_test, pred_probs_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights:\n",
    "- Results are same when we selected the PCA Component size selected manually and automatically\n",
    "- Lets understand the resuts better by validating them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_logistic_pred = pd.DataFrame({'Churn_Prob':pred_probs_train2})\n",
    "y_train_logistic_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Optimal Cutoff point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create columns with different probability cutoffs \n",
    "numbers = [float(x)/10 for x in range(10)]\n",
    "for i in numbers:\n",
    "    y_train_logistic_pred[i]= y_train_logistic_pred.Churn_Prob.map(lambda x: 1 if x > i else 0)\n",
    "y_train_logistic_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\n",
    "cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# TP = confusion[1,1] # true positive \n",
    "# TN = confusion[0,0] # true negatives\n",
    "# FP = confusion[0,1] # false positives\n",
    "# FN = confusion[1,0] # false negatives\n",
    "\n",
    "num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "for i in num:\n",
    "    cm1 = metrics.confusion_matrix(y_train_SMOTE, y_train_logistic_pred[i])\n",
    "    total1=sum(sum(cm1))\n",
    "    accuracy = (cm1[0,0]+cm1[1,1])/total1    \n",
    "    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
    "print(cutoff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot accuracy sensitivity and specificity for various probabilities.\n",
    "cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights and Observations**\n",
    "\n",
    "Sensitivity and Specificity balance each other at 0.5 probability which could be used as cut off to determine the churn and non churn cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs_test3=pred_probs_test2.copy()\n",
    "pred_probs_test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs_test3=(pred_probs_test3>=0.35)\n",
    "pred_probs_test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs_test3=pred_probs_test3.astype('int')\n",
    "pred_probs_test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, pred_probs_test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix(y_test, pred_probs_test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.accuracy_score(y_test, pred_probs_test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.recall_score(y_test, pred_probs_test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.precision_score(y_test, pred_probs_test3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "- The logistic regression post using pca is giving recall of 64% and accuracy of 87% \n",
    "- Let's use decision tree using pca variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc=DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.fit(df_train_pca2,y_train_SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=dc.predict(df_test_pca2)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "params = {\n",
    "    'max_depth': [2, 3, 5, 10, 20,25],\n",
    "    'min_samples_leaf': [5, 10, 20, 50, 100],\n",
    "    'criterion': [\"gini\", \"entropy\"]\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "folds=StratifiedKFold(n_splits=5,shuffle=True,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=dc, \n",
    "                           param_grid=params, \n",
    "                           cv=folds, n_jobs=-1, verbose=1, scoring = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_search.fit(df_train_pca2, y_train_SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame(grid_search.cv_results_)\n",
    "score_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_best = grid_search.best_estimator_\n",
    "dt_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc=DecisionTreeClassifier(criterion='entropy', max_depth=25, min_samples_leaf=5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.fit(df_train_pca2,y_train_SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=dc.predict(df_test_pca2)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.recall_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.precision_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights and Observations**\n",
    "- The recall is 28% and accuracy is 86%, which is much lower than what we were getting for logistic regression. We will concentrate on recall rather than accuracy as we want to find how many customers who actually churned - did the model correctly identify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search for hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_rf = RandomForestClassifier(random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_rf.fit(df_train_pca2,y_train_SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "params = {\n",
    "    'max_depth': [1, 2, 5, 10, 20],\n",
    "    'min_samples_leaf': [5, 10, 20, 50, 100],\n",
    "    'max_features': [2,3,4],\n",
    "    'n_estimators': [10, 30, 50, 100, 200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=classifier_rf, param_grid=params, \n",
    "                          cv=4, n_jobs=-1, verbose=1, scoring = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating model on training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Since random forest can manage class imbalance thus not giving SMOTE and PCA treated variables as input\n",
    "# On training set\n",
    "print(\"Train Accuracy :\", accuracy_score(y_train, rf_best.predict(X_train)))\n",
    "print(\"Train Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train, rf_best.predict(X_train)))\n",
    "# On testing set\n",
    "print(\"-\"*50)\n",
    "print(\"Test Accuracy :\", accuracy_score(y_test, rf_best.predict(X_test)))\n",
    "print(\"Test Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, rf_best.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights and Observations**\n",
    "- The recall and accuracy is clearly very poor, thus the most accurate model is PCA with Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable importance in RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_rf = RandomForestClassifier(random_state=42, n_jobs=-1, max_depth=20, n_estimators=200, oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_rf.fit(X_train_SMOTE, y_train_SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_df = pd.DataFrame({\n",
    "    \"Varname\": X_train.columns,\n",
    "    \"Imp\": classifier_rf.feature_importances_\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_df.sort_values(by=\"Imp\", ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 Model to define relationship between feature and target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using logistic regression and feature importance from random forest to identify useful features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting top 30 features\n",
    "\n",
    "# extract top 'n' features\n",
    "top_n = 30\n",
    "top_features = imp_df.Varname[0:top_n]\n",
    "top_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Logistic Regression on the above important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret_learner = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_int = X_train_SMOTE[top_features]\n",
    "X_test_int = X_test[top_features]\n",
    "print(X_train_int.shape)\n",
    "print(X_test_int.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_interpret = interpret_learner.fit(X_train_int , y_train_SMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs_train =model_interpret.predict_proba(X_train_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the roc_auc_score\n",
    "\"ROC AUC Score for training set is {:2.2}\".format(metrics.roc_auc_score(y_train_SMOTE, pred_probs_train[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs_test = model_interpret.predict_proba(X_test_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"ROC AUC Score for test set is {:2.2}\".format(metrics.roc_auc_score(y_test, pred_probs_test[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the coefficients from the logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefficients\n",
    "coefficients = model_interpret.coef_.reshape((30, 1)).tolist()\n",
    "coefficients = [val for sublist in coefficients for val in sublist]\n",
    "coefficients = [round(coefficient, 3) for coefficient in coefficients]\n",
    "\n",
    "logistic_features = list(X_train_int.columns)\n",
    "coefficients_df = pd.DataFrame(model_interpret.coef_, columns=logistic_features)\n",
    "\n",
    "# concatenate dataframes\n",
    "coefficients = pd.concat([coefficients_df], axis=1)\n",
    "\n",
    "#coefficients.sort_values(ascending=False)\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Business Insights**\n",
    "\n",
    "- Telecom company should analyze the rates being offered when a customer is roaming or calling outside india (ISD). The higher rates forces the customer to think of switching to a network which are cheaper. There is drastic drop in the calls made while roaming or outside country from June to August\n",
    "\n",
    "- Company can keep tabs when the customer reduces the calls within the network or outside network, it can only mean one thing that customer is trying to reduce the expense and plan to move to some other network. It could act as trigger for the salesperson to reach out to customer and resolve any pending issues or offer discounts\n",
    "\n",
    "- Incoming calls from some other networks increases that means saleperson from other network is trying to poach customer by offering them good deals. This could also act as trigger to get in touch with customer\n",
    "\n",
    "- Another trigger could be the reduction in the recharge amount in consecutive months\n",
    "\n",
    "- Company should also be cautious of new customers, churn is more for those who have newly joined\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TelcomChurn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
